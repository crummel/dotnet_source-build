From 1bf61b712c981ff8f068d19afc18e0870d0694fe Mon Sep 17 00:00:00 2001
From: Chris Rummel <crummel@microsoft.com>
Date: Thu, 19 Sep 2019 16:42:55 -0500
Subject: [PATCH 4/4] Remove SQLitePCLRaw dependency.

---
 .../Microsoft.CodeAnalysis.Workspaces.csproj  |   1 -
 .../Storage/SQLite/Interop/OpenFlags.cs       |  31 --
 .../SQLite/Interop/ResettableSqlStatement.cs  |  36 ---
 .../Portable/Storage/SQLite/Interop/Result.cs |  45 ---
 .../Storage/SQLite/Interop/SqlConnection.cs   | 295 -----------------
 .../Storage/SQLite/Interop/SqlException.cs    |  17 -
 .../Storage/SQLite/Interop/SqlStatement.cs    |  91 ------
 .../Storage/SQLite/PooledConnection.cs        |  28 --
 .../SQLitePersistentStorage.Accessor.cs       | 299 ------------------
 .../Storage/SQLite/SQLitePersistentStorage.cs | 296 -----------------
 .../SQLite/SQLitePersistentStorageService.cs  | 162 ----------
 ...SQLitePersistentStorage_BulkPopulateIds.cs | 239 --------------
 .../SQLitePersistentStorage_DocumentIds.cs    |  86 -----
 ...PersistentStorage_DocumentSerialization.cs |  49 ---
 .../SQLite/SQLitePersistentStorage_Helpers.cs | 153 ---------
 .../SQLitePersistentStorage_ProjectIds.cs     |  79 -----
 ...ePersistentStorage_ProjectSerialization.cs |  49 ---
 ...PersistentStorage_SolutionSerialization.cs |  48 ---
 .../SQLitePersistentStorage_StringIds.cs      | 179 -----------
 .../SQLitePersistentStorage_WriteBatching.cs  | 245 --------------
 20 files changed, 2428 deletions(-)
 delete mode 100644 src/Workspaces/Core/Portable/Storage/SQLite/Interop/OpenFlags.cs
 delete mode 100644 src/Workspaces/Core/Portable/Storage/SQLite/Interop/ResettableSqlStatement.cs
 delete mode 100644 src/Workspaces/Core/Portable/Storage/SQLite/Interop/Result.cs
 delete mode 100644 src/Workspaces/Core/Portable/Storage/SQLite/Interop/SqlConnection.cs
 delete mode 100644 src/Workspaces/Core/Portable/Storage/SQLite/Interop/SqlException.cs
 delete mode 100644 src/Workspaces/Core/Portable/Storage/SQLite/Interop/SqlStatement.cs
 delete mode 100644 src/Workspaces/Core/Portable/Storage/SQLite/PooledConnection.cs
 delete mode 100644 src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage.Accessor.cs
 delete mode 100644 src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage.cs
 delete mode 100644 src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorageService.cs
 delete mode 100644 src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage_BulkPopulateIds.cs
 delete mode 100644 src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage_DocumentIds.cs
 delete mode 100644 src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage_DocumentSerialization.cs
 delete mode 100644 src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage_Helpers.cs
 delete mode 100644 src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage_ProjectIds.cs
 delete mode 100644 src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage_ProjectSerialization.cs
 delete mode 100644 src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage_SolutionSerialization.cs
 delete mode 100644 src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage_StringIds.cs
 delete mode 100644 src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage_WriteBatching.cs

diff --git a/src/Workspaces/Core/Portable/Microsoft.CodeAnalysis.Workspaces.csproj b/src/Workspaces/Core/Portable/Microsoft.CodeAnalysis.Workspaces.csproj
index c467c0c8df..c994833587 100644
--- a/src/Workspaces/Core/Portable/Microsoft.CodeAnalysis.Workspaces.csproj
+++ b/src/Workspaces/Core/Portable/Microsoft.CodeAnalysis.Workspaces.csproj
@@ -24,7 +24,6 @@
     <ProjectReference Include="..\..\..\Compilers\Core\Portable\Microsoft.CodeAnalysis.csproj" />
   </ItemGroup>
   <ItemGroup>
-    <PackageReference Include="SQLitePCLRaw.bundle_green" Version="$(SQLitePCLRawbundle_greenVersion)" PrivateAssets="all" />
     <PackageReference Include="System.Composition" Version="$(SystemCompositionVersion)" />
   </ItemGroup>
   <ItemGroup Label="Linked Files">
diff --git a/src/Workspaces/Core/Portable/Storage/SQLite/Interop/OpenFlags.cs b/src/Workspaces/Core/Portable/Storage/SQLite/Interop/OpenFlags.cs
deleted file mode 100644
index 5401b5502e..0000000000
--- a/src/Workspaces/Core/Portable/Storage/SQLite/Interop/OpenFlags.cs
+++ /dev/null
@@ -1,31 +0,0 @@
-﻿// Copyright (c) Microsoft.  All Rights Reserved.  Licensed under the Apache License, Version 2.0.  See License.txt in the project root for license information.
-
-namespace Microsoft.CodeAnalysis.SQLite.Interop
-{
-    // From: https://sqlite.org/c3ref/c_open_autoproxy.html
-    // Uncomment what you need.  Leave the rest commented out to make it clear
-    // what we are/aren't using.
-    internal enum OpenFlags
-    {
-        // SQLITE_OPEN_READONLY         = 0x00000001, /* Ok for sqlite3_open_v2() */
-        SQLITE_OPEN_READWRITE = 0x00000002, /* Ok for sqlite3_open_v2() */
-        SQLITE_OPEN_CREATE = 0x00000004, /* Ok for sqlite3_open_v2() */
-        // SQLITE_OPEN_DELETEONCLOSE    = 0x00000008, /* VFS only */
-        // SQLITE_OPEN_EXCLUSIVE        = 0x00000010, /* VFS only */
-        // SQLITE_OPEN_AUTOPROXY        = 0x00000020, /* VFS only */
-        // SQLITE_OPEN_URI              = 0x00000040, /* Ok for sqlite3_open_v2() */
-        // SQLITE_OPEN_MEMORY           = 0x00000080, /* Ok for sqlite3_open_v2() */
-        // SQLITE_OPEN_MAIN_DB          = 0x00000100, /* VFS only */
-        // SQLITE_OPEN_TEMP_DB          = 0x00000200, /* VFS only */
-        // SQLITE_OPEN_TRANSIENT_DB     = 0x00000400, /* VFS only */
-        // SQLITE_OPEN_MAIN_JOURNAL     = 0x00000800, /* VFS only */
-        // SQLITE_OPEN_TEMP_JOURNAL     = 0x00001000, /* VFS only */
-        // SQLITE_OPEN_SUBJOURNAL       = 0x00002000, /* VFS only */
-        // SQLITE_OPEN_MASTER_JOURNAL   = 0x00004000, /* VFS only */
-        SQLITE_OPEN_NOMUTEX = 0x00008000, /* Ok for sqlite3_open_v2() */
-        // SQLITE_OPEN_FULLMUTEX        = 0x00010000, /* Ok for sqlite3_open_v2() */
-        // SQLITE_OPEN_SHAREDCACHE      = 0x00020000, /* Ok for sqlite3_open_v2() */
-        // SQLITE_OPEN_PRIVATECACHE     = 0x00040000, /* Ok for sqlite3_open_v2() */
-        // SQLITE_OPEN_WAL              = 0x00080000, /* VFS only */
-    }
-}
diff --git a/src/Workspaces/Core/Portable/Storage/SQLite/Interop/ResettableSqlStatement.cs b/src/Workspaces/Core/Portable/Storage/SQLite/Interop/ResettableSqlStatement.cs
deleted file mode 100644
index 35680bb281..0000000000
--- a/src/Workspaces/Core/Portable/Storage/SQLite/Interop/ResettableSqlStatement.cs
+++ /dev/null
@@ -1,36 +0,0 @@
-﻿// Copyright (c) Microsoft.  All Rights Reserved.  Licensed under the Apache License, Version 2.0.  See License.txt in the project root for license information.
-
-using System;
-
-namespace Microsoft.CodeAnalysis.SQLite.Interop
-{
-    /// <summary>
-    /// Simple wrapper struct for a <see cref="SqlStatement"/> that helps ensure that the statement
-    /// is always <see cref="SqlStatement.Reset"/> after it is used.
-    /// 
-    /// See https://sqlite.org/c3ref/stmt.html:
-    /// The life-cycle of a prepared statement object usually goes like this:
-    ///    1) Create the prepared statement object using sqlite3_prepare_v2().
-    ///    2) Bind values to parameters using the sqlite3_bind_* () interfaces.
-    ///    3) Run the SQL by calling sqlite3_step() one or more times.
-    ///    4) Reset the prepared statement using sqlite3_reset() then go back to step 2. Do this zero or more times.
-    ///    5) Destroy the object using sqlite3_finalize().
-    ///
-    /// This type helps ensure that '4' happens properly by clients executing statement.
-    /// Note that destroying/finalizing a statement is not the responsibility of a client
-    /// as it will happen to all prepared statemnets when the <see cref="SqlStatement"/> is
-    /// <see cref="SqlStatement.Close_OnlyForUseBySqlConnection"/>d.
-    /// </summary>
-    internal struct ResettableSqlStatement : IDisposable
-    {
-        public readonly SqlStatement Statement;
-
-        public ResettableSqlStatement(SqlStatement statement)
-        {
-            Statement = statement;
-        }
-
-        public void Dispose()
-            => Statement.Reset();
-    }
-}
diff --git a/src/Workspaces/Core/Portable/Storage/SQLite/Interop/Result.cs b/src/Workspaces/Core/Portable/Storage/SQLite/Interop/Result.cs
deleted file mode 100644
index 2b96fcb992..0000000000
--- a/src/Workspaces/Core/Portable/Storage/SQLite/Interop/Result.cs
+++ /dev/null
@@ -1,45 +0,0 @@
-﻿// Copyright (c) Microsoft.  All Rights Reserved.  Licensed under the Apache License, Version 2.0.  See License.txt in the project root for license information.
-
-
-using SQLitePCL;
-
-namespace Microsoft.CodeAnalysis.SQLite.Interop
-{
-    // From https://sqlite.org/c3ref/c_abort.html
-    // Uncomment what you need.  Leave the rest commented out to make it clear
-    // what we are/aren't using.
-    internal enum Result
-    {
-        OK = 0,                /* Successful result */
-        // ERROR = 1,          /* SQL error or missing database */
-        // INTERNAL = 2,       /* Internal logic error in SQLite */
-        // PERM = 3,           /* Access permission denied */
-        // ABORT = 4,          /* Callback routine requested an abort */
-        BUSY = 5,              /* The database file is locked */
-        LOCKED = 6,            /* A table in the database is locked */
-        NOMEM = 7,             /* A malloc() failed */
-        // READONLY = 8,       /* Attempt to write a readonly database */
-        // INTERRUPT = 9,      /* Operation terminated by sqlite3_interrupt()*/
-        IOERR = 10,            /* Some kind of disk I/O error occurred */
-        // CORRUPT = 11,       /* The database disk image is malformed */
-        // NOTFOUND = 12,      /* Unknown opcode in sqlite3_file_control() */
-        FULL = 13,             /* Insertion failed because database is full */
-        // CANTOPEN = 14,      /* Unable to open the database file */
-        // PROTOCOL = 15,      /* Database lock protocol error */
-        // EMPTY = 16,         /* Database is empty */
-        // SCHEMA = 17,        /* The database schema changed */
-        // TOOBIG = 18,        /* String or BLOB exceeds size limit */
-        CONSTRAINT = 19,       /* Abort due to constraint violation */
-        // MISMATCH = 20,      /* Data type mismatch */
-        // MISUSE = 21,        /* Library used incorrectly */
-        // NOLFS = 22,         /* Uses OS features not supported on host */
-        // AUTH = 23,          /* Authorization denied */
-        // FORMAT = 24,        /* Auxiliary database format error */
-        // RANGE = 25,         /* 2nd parameter to sqlite3_bind out of range */
-        // NOTADB = 26,        /* File opened that is not a database file */
-        // NOTICE = 27,        /* Notifications from sqlite3_log() */
-        // WARNING = 28,       /* Warnings from sqlite3_log() */
-        ROW = 100,             /* sqlite3_step() has another row ready */
-        DONE = 101             /* sqlite3_step() has finished executing */
-    }
-}
diff --git a/src/Workspaces/Core/Portable/Storage/SQLite/Interop/SqlConnection.cs b/src/Workspaces/Core/Portable/Storage/SQLite/Interop/SqlConnection.cs
deleted file mode 100644
index 2b0e620f03..0000000000
--- a/src/Workspaces/Core/Portable/Storage/SQLite/Interop/SqlConnection.cs
+++ /dev/null
@@ -1,295 +0,0 @@
-﻿// Copyright (c) Microsoft.  All Rights Reserved.  Licensed under the Apache License, Version 2.0.  See License.txt in the project root for license information.
-
-using System;
-using System.Collections.Generic;
-using System.Diagnostics;
-using System.IO;
-using Microsoft.CodeAnalysis.ErrorReporting;
-using Microsoft.CodeAnalysis.Host;
-using Roslyn.Utilities;
-using SQLitePCL;
-
-namespace Microsoft.CodeAnalysis.SQLite.Interop
-{
-    /// <summary>
-    /// Encapsulates a connection to a sqlite database.  On construction an attempt will be made
-    /// to open the DB if it exists, or create it if it does not.
-    /// 
-    /// Connections are considered relatively heavyweight and are pooled until the <see cref="SQLitePersistentStorage"/>
-    /// is <see cref="SQLitePersistentStorage.Dispose"/>d.  Connections can be used by different threads,
-    /// but only as long as they are used by one thread at a time.  They are not safe for concurrent
-    /// use by several threads.
-    /// 
-    /// <see cref="SqlStatement"/>s can be created through the user of <see cref="GetResettableStatement"/>.
-    /// These statements are cached for the lifetime of the connection and are only finalized
-    /// (i.e. destroyed) when the connection is closed.
-    /// </summary>
-    internal partial class SqlConnection
-    {
-        /// <summary>
-        /// The raw handle to the underlying DB.
-        /// </summary>
-        private readonly sqlite3 _handle;
-
-        /// <summary>
-        /// For testing purposes to simulate failures during testing.
-        /// </summary>
-        private readonly IPersistentStorageFaultInjector _faultInjector;
-
-        /// <summary>
-        /// Our cache of prepared statements for given sql strings.
-        /// </summary>
-        private readonly Dictionary<string, SqlStatement> _queryToStatement = new Dictionary<string, SqlStatement>();
-
-        /// <summary>
-        /// Whether or not we're in a transaction.  We currently don't supported nested transactions.
-        /// If we want that, we can achieve it through sqlite "save points".  However, that's adds a 
-        /// lot of complexity that is nice to avoid.
-        /// </summary>
-        public bool IsInTransaction { get; private set; }
-
-        public static SqlConnection Create(IPersistentStorageFaultInjector faultInjector, string databasePath)
-        {
-            faultInjector?.OnNewConnection();
-
-            // Use SQLITE_OPEN_NOMUTEX to enable multi-thread mode, where multiple connections can be used provided each
-            // one is only used from a single thread at a time.
-            // see https://sqlite.org/threadsafe.html for more detail
-            var flags = OpenFlags.SQLITE_OPEN_CREATE | OpenFlags.SQLITE_OPEN_READWRITE | OpenFlags.SQLITE_OPEN_NOMUTEX;
-            var result = (Result)raw.sqlite3_open_v2(databasePath, out var handle, (int)flags, vfs: null);
-
-            if (result != Result.OK)
-            {
-                throw new SqlException(result, $"Could not open database file: {databasePath} ({result})");
-            }
-
-            Contract.ThrowIfNull(handle);
-
-            raw.sqlite3_busy_timeout(handle, (int)TimeSpan.FromMinutes(1).TotalMilliseconds);
-
-            return new SqlConnection(faultInjector, handle);
-        }
-
-        private SqlConnection(IPersistentStorageFaultInjector faultInjector, sqlite3 handle)
-        {
-            _faultInjector = faultInjector;
-            _handle = handle;
-        }
-
-        ~SqlConnection()
-        {
-            if (!Environment.HasShutdownStarted)
-            {
-                var ex = new InvalidOperationException("SqlConnection was not properly closed");
-                _faultInjector?.OnFatalError(ex);
-                FatalError.Report(new InvalidOperationException("SqlConnection was not properly closed"));
-            }
-        }
-
-        internal void Close_OnlyForUseBySqlPersistentStorage()
-        {
-            GC.SuppressFinalize(this);
-
-            Contract.ThrowIfNull(_handle);
-
-            // release all the cached statements we have.
-            foreach (var statement in _queryToStatement.Values)
-            {
-                statement.Close_OnlyForUseBySqlConnection();
-            }
-
-            _queryToStatement.Clear();
-
-            // Finally close our handle to the actual DB.
-            ThrowIfNotOk(raw.sqlite3_close(_handle));
-        }
-
-        public void ExecuteCommand(string command, bool throwOnError = true)
-        {
-            using (var resettableStatement = GetResettableStatement(command))
-            {
-                var statement = resettableStatement.Statement;
-                var result = statement.Step(throwOnError);
-                if (result != Result.DONE && throwOnError)
-                {
-                    Throw(result);
-                }
-            }
-        }
-
-        public ResettableSqlStatement GetResettableStatement(string query)
-        {
-            if (!_queryToStatement.TryGetValue(query, out var statement))
-            {
-                var result = (Result)raw.sqlite3_prepare_v2(_handle, query, out var rawStatement);
-                ThrowIfNotOk(result);
-                statement = new SqlStatement(this, rawStatement);
-                _queryToStatement[query] = statement;
-            }
-
-            return new ResettableSqlStatement(statement);
-        }
-
-        public void RunInTransaction<TState>(Action<TState> action, TState state)
-        {
-            RunInTransaction(
-                state =>
-                {
-                    state.action(state.state);
-                    return (object)null;
-                },
-                (action, state));
-        }
-
-        public TResult RunInTransaction<TState, TResult>(Func<TState, TResult> action, TState state)
-        {
-            try
-            {
-                if (IsInTransaction)
-                {
-                    throw new InvalidOperationException("Nested transactions not currently supported");
-                }
-
-                IsInTransaction = true;
-
-                ExecuteCommand("begin transaction");
-                var result = action(state);
-                ExecuteCommand("commit transaction");
-                return result;
-            }
-            catch (SqlException ex) when (ex.Result == Result.FULL ||
-                                          ex.Result == Result.IOERR ||
-                                          ex.Result == Result.BUSY ||
-                                          ex.Result == Result.LOCKED ||
-                                          ex.Result == Result.NOMEM)
-            {
-                // See documentation here: https://sqlite.org/lang_transaction.html
-                // If certain kinds of errors occur within a transaction, the transaction 
-                // may or may not be rolled back automatically. The errors that can cause 
-                // an automatic rollback include:
-
-                // SQLITE_FULL: database or disk full
-                // SQLITE_IOERR: disk I/ O error
-                // SQLITE_BUSY: database in use by another process
-                // SQLITE_LOCKED: database in use by another connection in the same process
-                // SQLITE_NOMEM: out or memory
-
-                // It is recommended that applications respond to the errors listed above by
-                // explicitly issuing a ROLLBACK command. If the transaction has already been
-                // rolled back automatically by the error response, then the ROLLBACK command 
-                // will fail with an error, but no harm is caused by this.
-                Rollback(throwOnError: false);
-                throw;
-            }
-            catch (Exception)
-            {
-                Rollback(throwOnError: true);
-                throw;
-            }
-            finally
-            {
-                IsInTransaction = false;
-            }
-        }
-
-        private void Rollback(bool throwOnError)
-            => ExecuteCommand("rollback transaction", throwOnError);
-
-        public int LastInsertRowId()
-            => (int)raw.sqlite3_last_insert_rowid(_handle);
-
-        [PerformanceSensitive("https://github.com/dotnet/roslyn/issues/36114", AllowCaptures = false)]
-        public Stream ReadBlob_MustRunInTransaction(string tableName, string columnName, long rowId)
-        {
-            // NOTE: we do need to do the blob reading in a transaction because of the
-            // following: https://www.sqlite.org/c3ref/blob_open.html
-            //
-            // If the row that a BLOB handle points to is modified by an UPDATE, DELETE, 
-            // or by ON CONFLICT side-effects then the BLOB handle is marked as "expired".
-            // This is true if any column of the row is changed, even a column other than
-            // the one the BLOB handle is open on. Calls to sqlite3_blob_read() and 
-            // sqlite3_blob_write() for an expired BLOB handle fail with a return code of
-            // SQLITE_ABORT.
-            if (!IsInTransaction)
-            {
-                throw new InvalidOperationException("Must read blobs within a transaction to prevent corruption!");
-            }
-
-            const int ReadOnlyFlags = 0;
-            var result = raw.sqlite3_blob_open(_handle, "main", tableName, columnName, rowId, ReadOnlyFlags, out var blob);
-            if (result == raw.SQLITE_ERROR)
-            {
-                // can happen when rowId points to a row that hasn't been written to yet.
-                return null;
-            }
-
-            ThrowIfNotOk(result);
-            try
-            {
-                return ReadBlob(blob);
-            }
-            finally
-            {
-                ThrowIfNotOk(raw.sqlite3_blob_close(blob));
-            }
-        }
-
-        private Stream ReadBlob(sqlite3_blob blob)
-        {
-            var length = raw.sqlite3_blob_bytes(blob);
-
-            // If it's a small blob, just read it into one of our pooled arrays, and then
-            // create a PooledStream over it. 
-            if (length <= SQLitePersistentStorage.MaxPooledByteArrayLength)
-            {
-                return ReadBlobIntoPooledStream(blob, length);
-            }
-            else
-            {
-                // Otherwise, it's a large stream.  Just take the hit of allocating.
-                var bytes = new byte[length];
-                ThrowIfNotOk(raw.sqlite3_blob_read(blob, bytes, length, offset: 0));
-                return new MemoryStream(bytes);
-            }
-        }
-
-        private Stream ReadBlobIntoPooledStream(sqlite3_blob blob, int length)
-        {
-            var bytes = SQLitePersistentStorage.GetPooledBytes();
-            try
-            {
-                ThrowIfNotOk(raw.sqlite3_blob_read(blob, bytes, length, offset: 0));
-
-                // Copy those bytes into a pooled stream
-                return SerializableBytes.CreateReadableStream(bytes, length);
-            }
-            finally
-            {
-                // Return our small array back to the pool.
-                SQLitePersistentStorage.ReturnPooledBytes(bytes);
-            }
-        }
-
-        public void ThrowIfNotOk(int result)
-            => ThrowIfNotOk((Result)result);
-
-        public void ThrowIfNotOk(Result result)
-            => ThrowIfNotOk(_handle, result);
-
-        public static void ThrowIfNotOk(sqlite3 handle, Result result)
-        {
-            if (result != Result.OK)
-            {
-                Throw(handle, result);
-            }
-        }
-
-        public void Throw(Result result)
-            => Throw(_handle, result);
-
-        public static void Throw(sqlite3 handle, Result result)
-            => throw new SqlException(result,
-                raw.sqlite3_errmsg(handle) + "\r\n" +
-                raw.sqlite3_errstr(raw.sqlite3_extended_errcode(handle)));
-    }
-}
diff --git a/src/Workspaces/Core/Portable/Storage/SQLite/Interop/SqlException.cs b/src/Workspaces/Core/Portable/Storage/SQLite/Interop/SqlException.cs
deleted file mode 100644
index f4a4da4e9c..0000000000
--- a/src/Workspaces/Core/Portable/Storage/SQLite/Interop/SqlException.cs
+++ /dev/null
@@ -1,17 +0,0 @@
-﻿// Copyright (c) Microsoft.  All Rights Reserved.  Licensed under the Apache License, Version 2.0.  See License.txt in the project root for license information.
-
-using System;
-
-namespace Microsoft.CodeAnalysis.SQLite.Interop
-{
-    internal class SqlException : Exception
-    {
-        public readonly Result Result;
-
-        public SqlException(Result result, string message)
-            : base(message)
-        {
-            this.Result = result;
-        }
-    }
-}
diff --git a/src/Workspaces/Core/Portable/Storage/SQLite/Interop/SqlStatement.cs b/src/Workspaces/Core/Portable/Storage/SQLite/Interop/SqlStatement.cs
deleted file mode 100644
index ba38743de4..0000000000
--- a/src/Workspaces/Core/Portable/Storage/SQLite/Interop/SqlStatement.cs
+++ /dev/null
@@ -1,91 +0,0 @@
-﻿// Copyright (c) Microsoft.  All Rights Reserved.  Licensed under the Apache License, Version 2.0.  See License.txt in the project root for license information.
-
-using System;
-using System.Runtime.InteropServices;
-using Roslyn.Utilities;
-using SQLitePCL;
-
-namespace Microsoft.CodeAnalysis.SQLite.Interop
-{
-    /// <summary>
-    /// Represents a prepared sqlite statement.  <see cref="SqlStatement"/>s can be 
-    /// <see cref="Step"/>ed (i.e. executed).  Executing a statement can result in 
-    /// either <see cref="Result.DONE"/> if the command completed and produced no
-    /// value, or <see cref="Result.ROW"/> if it evaluated out to a sql row that can
-    /// then be queried.
-    /// 
-    /// If a statement is parameterized then parameters can be provided by the 
-    /// BindXXX overloads.  Bind is 1-based (to match sqlite).  
-    /// 
-    /// When done executing a statement, the statement should be <see cref="Reset"/>.
-    /// The easiest way to ensure this is to just use a 'using' statement along with
-    /// a <see cref="ResettableSqlStatement"/>.  By resetting the statement, it can
-    /// then be used in the future with new bound parameters.
-    /// 
-    /// Finalization/destruction of the underlying raw sqlite statement is handled
-    /// by <see cref="SqlConnection.Close_OnlyForUseBySqlPersistentStorage"/>.
-    /// </summary>
-    internal struct SqlStatement
-    {
-        private readonly SqlConnection _connection;
-        private readonly sqlite3_stmt _rawStatement;
-
-        public SqlStatement(SqlConnection connection, sqlite3_stmt statement)
-        {
-            _connection = connection;
-            _rawStatement = statement;
-        }
-
-        internal void Close_OnlyForUseBySqlConnection()
-            => _connection.ThrowIfNotOk(raw.sqlite3_finalize(_rawStatement));
-
-        public void Reset()
-            => _connection.ThrowIfNotOk(raw.sqlite3_reset(_rawStatement));
-
-        public Result Step(bool throwOnError = true)
-        {
-            var stepResult = (Result)raw.sqlite3_step(_rawStatement);
-
-            // Anything other than DONE or ROW is an error when stepping.
-            // throw if the caller wants that, or just return the value
-            // otherwise.
-            if (stepResult != Result.DONE && stepResult != Result.ROW)
-            {
-                if (throwOnError)
-                {
-                    _connection.Throw(stepResult);
-                    throw ExceptionUtilities.Unreachable;
-                }
-            }
-
-            return stepResult;
-        }
-
-        internal void BindStringParameter(int parameterIndex, string value)
-            => _connection.ThrowIfNotOk(raw.sqlite3_bind_text(_rawStatement, parameterIndex, value));
-
-        internal void BindInt64Parameter(int parameterIndex, long value)
-            => _connection.ThrowIfNotOk(raw.sqlite3_bind_int64(_rawStatement, parameterIndex, value));
-
-        // SQLite PCL does not expose sqlite3_bind_blob function that takes a length.  So we explicitly
-        // DLL import it here.  See https://github.com/ericsink/SQLitePCL.raw/issues/135
-
-        internal void BindBlobParameter(int parameterIndex, byte[] value, int length)
-            => _connection.ThrowIfNotOk(sqlite3_bind_blob(_rawStatement.ptr, parameterIndex, value, length, new IntPtr(-1)));
-
-        [DllImport("e_sqlite3.dll", ExactSpelling = true, CallingConvention = CallingConvention.Cdecl)]
-        public static extern int sqlite3_bind_blob(IntPtr stmt, int index, byte[] val, int nSize, IntPtr nTransient);
-
-        internal byte[] GetBlobAt(int columnIndex)
-            => raw.sqlite3_column_blob(_rawStatement, columnIndex);
-
-        internal int GetInt32At(int columnIndex)
-            => raw.sqlite3_column_int(_rawStatement, columnIndex);
-
-        internal long GetInt64At(int columnIndex)
-            => raw.sqlite3_column_int64(_rawStatement, columnIndex);
-
-        internal string GetStringAt(int columnIndex)
-            => raw.sqlite3_column_text(_rawStatement, columnIndex);
-    }
-}
diff --git a/src/Workspaces/Core/Portable/Storage/SQLite/PooledConnection.cs b/src/Workspaces/Core/Portable/Storage/SQLite/PooledConnection.cs
deleted file mode 100644
index 563729724d..0000000000
--- a/src/Workspaces/Core/Portable/Storage/SQLite/PooledConnection.cs
+++ /dev/null
@@ -1,28 +0,0 @@
-﻿// Copyright (c) Microsoft.  All Rights Reserved.  Licensed under the Apache License, Version 2.0.  See License.txt in the project root for license information.
-
-using System;
-using Microsoft.CodeAnalysis.Host;
-using Microsoft.CodeAnalysis.SQLite.Interop;
-
-namespace Microsoft.CodeAnalysis.SQLite
-{
-    internal partial class SQLitePersistentStorage : AbstractPersistentStorage
-    {
-        private struct PooledConnection : IDisposable
-        {
-            private readonly SQLitePersistentStorage sqlitePersistentStorage;
-            public readonly SqlConnection Connection;
-
-            public PooledConnection(SQLitePersistentStorage sqlitePersistentStorage, SqlConnection sqlConnection)
-            {
-                this.sqlitePersistentStorage = sqlitePersistentStorage;
-                Connection = sqlConnection;
-            }
-
-            public void Dispose()
-            {
-                sqlitePersistentStorage.ReleaseConnection(Connection);
-            }
-        }
-    }
-}
diff --git a/src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage.Accessor.cs b/src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage.Accessor.cs
deleted file mode 100644
index c6cfcd53bf..0000000000
--- a/src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage.Accessor.cs
+++ /dev/null
@@ -1,299 +0,0 @@
-﻿// Copyright (c) Microsoft.  All Rights Reserved.  Licensed under the Apache License, Version 2.0.  See License.txt in the project root for license information.
-
-using System;
-using System.Collections.Generic;
-using System.Diagnostics;
-using System.IO;
-using System.Linq;
-using System.Threading;
-using System.Threading.Tasks;
-using Microsoft.CodeAnalysis.PooledObjects;
-using Microsoft.CodeAnalysis.SQLite.Interop;
-using Microsoft.CodeAnalysis.Storage;
-using Roslyn.Utilities;
-
-namespace Microsoft.CodeAnalysis.SQLite
-{
-    internal partial class SQLitePersistentStorage
-    {
-        /// <summary>
-        /// Abstracts out access to specific tables in the DB.  This allows us to share overall
-        /// logic around cancellation/pooling/error-handling/etc, while still hitting different
-        /// db tables.
-        /// </summary>
-        private abstract class Accessor<TKey, TWriteQueueKey, TDatabaseId>
-        {
-            protected readonly SQLitePersistentStorage Storage;
-            private readonly string _select_rowid_from_0_where_1;
-            private readonly string _insert_or_replace_into_0_1_2_3_value;
-
-            /// <summary>
-            /// Queue of actions we want to perform all at once against the DB in a single transaction.
-            /// </summary>
-            private readonly MultiDictionary<TWriteQueueKey, Action<SqlConnection>> _writeQueueKeyToWrites =
-                new MultiDictionary<TWriteQueueKey, Action<SqlConnection>>();
-
-            /// <summary>
-            /// The task responsible for writing out all the batched actions we have for a particular
-            /// queue.  When new reads come in for that queue they can 'await' this write-task completing
-            /// so that all reads for the queue observe any previously completed writes.
-            /// </summary>
-            private readonly Dictionary<TWriteQueueKey, Task> _writeQueueKeyToWriteTask =
-                new Dictionary<TWriteQueueKey, Task>();
-
-            public Accessor(SQLitePersistentStorage storage)
-            {
-                Storage = storage;
-                _select_rowid_from_0_where_1 = $@"select rowid from ""{DataTableName}"" where ""{DataIdColumnName}"" = ?";
-                _insert_or_replace_into_0_1_2_3_value = $@"insert or replace into ""{DataTableName}""(""{DataIdColumnName}"",""{ChecksumColumnName}"",""{DataColumnName}"") values (?,?,?)";
-            }
-
-            protected abstract string DataTableName { get; }
-
-            protected abstract bool TryGetDatabaseId(SqlConnection connection, TKey key, out TDatabaseId dataId);
-            protected abstract void BindFirstParameter(SqlStatement statement, TDatabaseId dataId);
-            protected abstract TWriteQueueKey GetWriteQueueKey(TKey key);
-
-            public async Task<Checksum> ReadChecksumAsync(TKey key, CancellationToken cancellationToken)
-            {
-                using (var stream = await ReadBlobColumnAsync(key, ChecksumColumnName, checksumOpt: null, cancellationToken).ConfigureAwait(false))
-                using (var reader = ObjectReader.TryGetReader(stream, cancellationToken))
-                {
-                    if (reader != null)
-                    {
-                        return Checksum.ReadFrom(reader);
-                    }
-                }
-
-                return null;
-            }
-
-            public Task<Stream> ReadStreamAsync(TKey key, Checksum checksum, CancellationToken cancellationToken)
-                => ReadBlobColumnAsync(key, DataColumnName, checksum, cancellationToken);
-
-            private async Task<Stream> ReadBlobColumnAsync(
-                TKey key, string columnName, Checksum checksumOpt, CancellationToken cancellationToken)
-            {
-                cancellationToken.ThrowIfCancellationRequested();
-
-                if (!Storage._shutdownTokenSource.IsCancellationRequested)
-                {
-                    bool haveDataId;
-                    TDatabaseId dataId;
-                    using (var pooledConnection = Storage.GetPooledConnection())
-                    {
-                        haveDataId = TryGetDatabaseId(pooledConnection.Connection, key, out dataId);
-                    }
-
-                    if (haveDataId)
-                    {
-                        // Ensure all pending document writes to this name are flushed to the DB so that 
-                        // we can find them below.
-                        await FlushPendingWritesAsync(key, cancellationToken).ConfigureAwait(false);
-
-                        try
-                        {
-                            using (var pooledConnection = Storage.GetPooledConnection())
-                            {
-                                // Lookup the row from the DocumentData table corresponding to our dataId.
-                                return ReadBlob(
-                                    pooledConnection.Connection, dataId, columnName,
-                                    checksumOpt, cancellationToken);
-                            }
-                        }
-                        catch (Exception ex)
-                        {
-                            StorageDatabaseLogger.LogException(ex);
-                        }
-                    }
-                }
-
-                return null;
-            }
-
-            public async Task<bool> WriteStreamAsync(
-                TKey key, Stream stream, Checksum checksumOpt, CancellationToken cancellationToken)
-            {
-                // Note: we're technically fully synchronous.  However, we're called from several
-                // async methods.  We just return a Task<bool> here so that all our callers don't
-                // need to call Task.FromResult on us.
-
-                cancellationToken.ThrowIfCancellationRequested();
-
-                if (!Storage._shutdownTokenSource.IsCancellationRequested)
-                {
-                    bool haveDataId;
-                    TDatabaseId dataId;
-                    using (var pooledConnection = Storage.GetPooledConnection())
-                    {
-                        // Determine the appropriate data-id to store this stream at.
-                        haveDataId = TryGetDatabaseId(pooledConnection.Connection, key, out dataId);
-                    }
-
-                    if (haveDataId)
-                    {
-                        var (checksumBytes, checksumLength, checksumPooled) = GetBytes(checksumOpt, cancellationToken);
-                        var (dataBytes, dataLength, dataPooled) = GetBytes(stream);
-
-                        await AddWriteTaskAsync(key, con =>
-                        {
-                            InsertOrReplaceBlob(con, dataId,
-                                checksumBytes, checksumLength,
-                                dataBytes, dataLength);
-                            if (dataPooled)
-                            {
-                                ReturnPooledBytes(dataBytes);
-                            }
-
-                            if (checksumPooled)
-                            {
-                                ReturnPooledBytes(checksumBytes);
-                            }
-                        }, cancellationToken).ConfigureAwait(false);
-
-                        return true;
-                    }
-                }
-
-                return false;
-            }
-
-            private Task FlushPendingWritesAsync(TKey key, CancellationToken cancellationToken)
-                => Storage.FlushSpecificWritesAsync(_writeQueueKeyToWrites, _writeQueueKeyToWriteTask, GetWriteQueueKey(key), cancellationToken);
-
-            private Task AddWriteTaskAsync(TKey key, Action<SqlConnection> action, CancellationToken cancellationToken)
-                => Storage.AddWriteTaskAsync(_writeQueueKeyToWrites, GetWriteQueueKey(key), action, cancellationToken);
-
-            private Stream ReadBlob(
-                SqlConnection connection, TDatabaseId dataId, string columnName,
-                Checksum checksumOpt, CancellationToken cancellationToken)
-            {
-                // Note: it's possible that someone may write to this row between when we
-                // get the row ID above and now.  That's fine.  We'll just read the new
-                // bytes that have been written to this location.  Note that only the
-                // data for a row in our system can change, the ID will always stay the
-                // same, and the data will always be valid for our ID.  So there is no
-                // safety issue here.
-                if (TryGetRowId(connection, dataId, out var rowId))
-                {
-                    // Have to run the blob reading in a transaction.  This is necessary
-                    // for two reasons.  First, blob reading outside a transaction is not
-                    // safe to do with the sqlite API.  It may produce corrupt bits if 
-                    // another thread is writing to the blob.  Second, if a checksum was
-                    // passed in, we need to validate that the checksums match.  This is
-                    // only safe if we are in a transaction and no-one else can race with
-                    // us.
-                    return connection.RunInTransaction((tuple) =>
-                    {
-                        // If we were passed a checksum, make sure it matches what we have
-                        // stored in the table already.  If they don't match, don't read
-                        // out the data value at all.
-                        if (tuple.checksumOpt != null &&
-                            !ChecksumsMatch_MustRunInTransaction(tuple.connection, tuple.rowId, tuple.checksumOpt, cancellationToken))
-                        {
-                            return null;
-                        }
-
-                        return connection.ReadBlob_MustRunInTransaction(tuple.self.DataTableName, tuple.columnName, tuple.rowId);
-                    }, (self: this, connection, columnName, checksumOpt, rowId));
-                }
-
-                return null;
-            }
-
-            private bool ChecksumsMatch_MustRunInTransaction(SqlConnection connection, long rowId, Checksum checksum, CancellationToken cancellationToken)
-            {
-                using (var checksumStream = connection.ReadBlob_MustRunInTransaction(DataTableName, ChecksumColumnName, rowId))
-                using (var reader = ObjectReader.TryGetReader(checksumStream, cancellationToken))
-                {
-                    return reader != null && Checksum.ReadFrom(reader) == checksum;
-                }
-            }
-
-            protected bool GetAndVerifyRowId(SqlConnection connection, long dataId, out long rowId)
-            {
-                // For the Document and Project tables, our dataId is our rowId:
-                // 
-                // https://sqlite.org/lang_createtable.html
-                // if a rowid table has a primary key that consists of a single column and the 
-                // declared type of that column is "INTEGER" in any mixture of upper and lower 
-                // case, then the column becomes an alias for the rowid. Such a column is usually
-                // referred to as an "integer primary key". A PRIMARY KEY column only becomes an
-                // integer primary key if the declared type name is exactly "INTEGER"
-#if DEBUG
-                // make sure that if we actually request the rowId from the database that it
-                // is equal to our data id.  Only do this in debug as this can be expensive
-                // and we definitely do not want to do this in release.
-                if (TryGetRowIdWorker(connection, (TDatabaseId)(object)dataId, out rowId))
-                {
-                    Debug.Assert(dataId == rowId);
-                }
-#endif
-
-                // Can just return out dataId as the rowId without actually having to hit the 
-                // database at all.
-                rowId = dataId;
-                return true;
-            }
-
-            protected virtual bool TryGetRowId(SqlConnection connection, TDatabaseId dataId, out long rowId)
-                => TryGetRowIdWorker(connection, dataId, out rowId);
-
-            private bool TryGetRowIdWorker(SqlConnection connection, TDatabaseId dataId, out long rowId)
-            {
-                // See https://sqlite.org/autoinc.html
-                // > In SQLite, table rows normally have a 64-bit signed integer ROWID which is 
-                // unique among all rows in the same table. (WITHOUT ROWID tables are the exception.)
-                // 
-                // You can access the ROWID of an SQLite table using one of the special column names 
-                // ROWID, _ROWID_, or OID. Except if you declare an ordinary table column to use one 
-                // of those special names, then the use of that name will refer to the declared column
-                // not to the internal ROWID.
-                using (var resettableStatement = connection.GetResettableStatement(_select_rowid_from_0_where_1))
-                {
-                    var statement = resettableStatement.Statement;
-
-                    // Binding indices are 1-based.
-                    BindFirstParameter(statement, dataId);
-
-                    var stepResult = statement.Step();
-                    if (stepResult == Result.ROW)
-                    {
-                        rowId = statement.GetInt64At(columnIndex: 0);
-                        return true;
-                    }
-                }
-
-                rowId = -1;
-                return false;
-            }
-
-            private void InsertOrReplaceBlob(
-                SqlConnection connection, TDatabaseId dataId,
-                byte[] checksumBytes, int checksumLength,
-                byte[] dataBytes, int dataLength)
-            {
-                using (var resettableStatement = connection.GetResettableStatement(_insert_or_replace_into_0_1_2_3_value))
-                {
-                    var statement = resettableStatement.Statement;
-
-                    // Binding indices are 1 based.
-                    BindFirstParameter(statement, dataId);
-                    statement.BindBlobParameter(parameterIndex: 2, value: checksumBytes, length: checksumLength);
-                    statement.BindBlobParameter(parameterIndex: 3, value: dataBytes, length: dataLength);
-
-                    statement.Step();
-                }
-            }
-
-            public void AddAndClearAllPendingWrites(ArrayBuilder<Action<SqlConnection>> result)
-            {
-                // Copy the pending work we have to the result copy.
-                result.AddRange(_writeQueueKeyToWrites.SelectMany(kvp => kvp.Value));
-
-                // Clear out the collection so we don't process things multiple times.
-                _writeQueueKeyToWrites.Clear();
-            }
-        }
-    }
-}
diff --git a/src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage.cs b/src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage.cs
deleted file mode 100644
index 0323065778..0000000000
--- a/src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage.cs
+++ /dev/null
@@ -1,296 +0,0 @@
-﻿// Copyright (c) Microsoft.  All Rights Reserved.  Licensed under the Apache License, Version 2.0.  See License.txt in the project root for license information.
-
-using System;
-using System.Collections.Generic;
-using System.IO;
-using System.Threading;
-using Microsoft.CodeAnalysis.Host;
-using Microsoft.CodeAnalysis.Options;
-using Microsoft.CodeAnalysis.SQLite.Interop;
-using Microsoft.CodeAnalysis.Storage;
-
-namespace Microsoft.CodeAnalysis.SQLite
-{
-    /// <summary>
-    /// Implementation of an <see cref="IPersistentStorage"/> backed by SQLite.
-    /// </summary>
-    internal partial class SQLitePersistentStorage : AbstractPersistentStorage
-    {
-        // Version history.
-        // 1. Initial use of sqlite as the persistence layer.  Simple key->value storage tables.
-        // 2. Updated to store checksums.  Tables now key->(checksum,value).  Allows for reading
-        //    and validating checksums without the overhead of reading the full 'value' into
-        //    memory.
-        private const string Version = "2";
-
-        /// <summary>
-        /// Inside the DB we have a table dedicated to storing strings that also provides a unique 
-        /// integral ID per string.  This allows us to store data keyed in a much more efficient
-        /// manner as we can use those IDs instead of duplicating strings all over the place.  For
-        /// example, there may be many pieces of data associated with a file.  We don't want to 
-        /// key off the file path in all these places as that would cause a large amount of bloat.
-        /// 
-        /// Because the string table can map from arbitrary strings to unique IDs, it can also be
-        /// used to create IDs for compound objects.  For example, given the IDs for the FilePath
-        /// and Name of a Project, we can get an ID that represents the project itself by just
-        /// creating a compound key of those two IDs.  This ID can then be used in other compound
-        /// situations.  For example, a Document's ID is creating by compounding its Project's 
-        /// ID, along with the IDs for the Document's FilePath and Name.
-        /// 
-        /// The format of the table is:
-        /// 
-        ///  StringInfo
-        ///  --------------------------------------------------------------
-        ///  | Id (integer, primary key, auto increment) | Data (varchar) |
-        ///  --------------------------------------------------------------
-        /// </summary>
-        private const string StringInfoTableName = "StringInfo" + Version;
-
-        /// <summary>
-        /// Inside the DB we have a table for data corresponding to the <see cref="Solution"/>.  The 
-        /// data is just a blob that is keyed by a string Id.  Data with this ID can be retrieved
-        /// or overwritten.
-        /// 
-        /// The format of the table is:
-        /// 
-        ///  SolutionData
-        ///  -------------------------------------------------------------------
-        ///  | DataId (primary key, varchar) | | Checksum (blob) | Data (blob) |
-        ///  -------------------------------------------------------------------
-        /// </summary>
-        private const string SolutionDataTableName = "SolutionData" + Version;
-
-        /// <summary>
-        /// Inside the DB we have a table for data that we want associated with a <see cref="Project"/>.
-        /// The data is keyed off of an integral value produced by combining the ID of the Project and
-        /// the ID of the name of the data (see <see cref="SQLitePersistentStorage.ReadStreamAsync(Project, string, Checksum, CancellationToken)"/>.
-        /// 
-        /// This gives a very efficient integral key, and means that the we only have to store a 
-        /// single mapping from stream name to ID in the string table.
-        /// 
-        /// The format of the table is:
-        /// 
-        ///  ProjectData
-        ///  -------------------------------------------------------------------
-        ///  | DataId (primary key, integer) | | Checksum (blob) | Data (blob) |
-        ///  -------------------------------------------------------------------
-        /// </summary>
-        private const string ProjectDataTableName = "ProjectData" + Version;
-
-        /// <summary>
-        /// Inside the DB we have a table for data that we want associated with a <see cref="Document"/>.
-        /// The data is keyed off of an integral value produced by combining the ID of the Document and
-        /// the ID of the name of the data (see <see cref="SQLitePersistentStorage.ReadStreamAsync(Document, string, Checksum, CancellationToken)"/>.
-        /// 
-        /// This gives a very efficient integral key, and means that the we only have to store a 
-        /// single mapping from stream name to ID in the string table.
-        /// 
-        /// The format of the table is:
-        /// 
-        ///  DocumentData
-        ///  -------------------------------------------------------------------
-        ///  | DataId (primary key, integer) | | Checksum (blob) | Data (blob) |
-        ///  -------------------------------------------------------------------
-        /// </summary>
-        private const string DocumentDataTableName = "DocumentData" + Version;
-
-        private const string DataIdColumnName = "DataId";
-        private const string ChecksumColumnName = "Checksum";
-        private const string DataColumnName = "Data";
-
-        private readonly CancellationTokenSource _shutdownTokenSource = new CancellationTokenSource();
-
-        private readonly IDisposable _dbOwnershipLock;
-        private readonly IPersistentStorageFaultInjector _faultInjectorOpt;
-
-        // Accessors that allow us to retrieve/store data into specific DB tables.  The
-        // core Accessor type has logic that we to share across all reading/writing, while
-        // the derived types contain only enough logic to specify how to read/write from
-        // their respective tables.
-
-        private readonly SolutionAccessor _solutionAccessor;
-        private readonly ProjectAccessor _projectAccessor;
-        private readonly DocumentAccessor _documentAccessor;
-
-        // cached query strings
-
-        private readonly string _select_star_from_0;
-        private readonly string _insert_into_0_1_values;
-        private readonly string _select_star_from_0_where_1_limit_one;
-
-        // We pool connections to the DB so that we don't have to take the hit of 
-        // reconnecting.  The connections also cache the prepared statements used
-        // to get/set data from the db.  A connection is safe to use by one thread
-        // at a time, but is not safe for simultaneous use by multiple threads.
-        private readonly object _connectionGate = new object();
-        private readonly Stack<SqlConnection> _connectionsPool = new Stack<SqlConnection>();
-
-        public SQLitePersistentStorage(
-            string workingFolderPath,
-            string solutionFilePath,
-            string databaseFile,
-            IDisposable dbOwnershipLock,
-            IPersistentStorageFaultInjector faultInjectorOpt)
-            : base(workingFolderPath, solutionFilePath, databaseFile)
-        {
-            _dbOwnershipLock = dbOwnershipLock;
-            _faultInjectorOpt = faultInjectorOpt;
-
-            _solutionAccessor = new SolutionAccessor(this);
-            _projectAccessor = new ProjectAccessor(this);
-            _documentAccessor = new DocumentAccessor(this);
-
-            _select_star_from_0 = $@"select * from ""{StringInfoTableName}""";
-            _insert_into_0_1_values = $@"insert into ""{StringInfoTableName}""(""{DataColumnName}"") values (?)";
-            _select_star_from_0_where_1_limit_one = $@"select * from ""{StringInfoTableName}"" where (""{DataColumnName}"" = ?) limit 1";
-        }
-
-        private SqlConnection GetConnection()
-        {
-            lock (_connectionGate)
-            {
-                // If we have an available connection, just return that.
-                if (_connectionsPool.Count > 0)
-                {
-                    return _connectionsPool.Pop();
-                }
-            }
-
-            // Otherwise create a new connection.
-            return SqlConnection.Create(_faultInjectorOpt, DatabaseFile);
-        }
-
-        private void ReleaseConnection(SqlConnection connection)
-        {
-            lock (_connectionGate)
-            {
-                // If we've been asked to shutdown, then don't actually add the connection back to 
-                // the pool.  Instead, just close it as we no longer need it.
-                if (_shutdownTokenSource.IsCancellationRequested)
-                {
-                    connection.Close_OnlyForUseBySqlPersistentStorage();
-                    return;
-                }
-
-                _connectionsPool.Push(connection);
-            }
-        }
-
-        public override void Dispose()
-        {
-            // Flush all pending writes so that all data our features wanted written
-            // are definitely persisted to the DB.
-            try
-            {
-                CloseWorker();
-            }
-            finally
-            {
-                // let the lock go
-                _dbOwnershipLock.Dispose();
-            }
-        }
-
-        private void CloseWorker()
-        {
-            // Flush all pending writes so that all data our features wanted written
-            // are definitely persisted to the DB.
-            try
-            {
-                FlushAllPendingWritesAsync(CancellationToken.None).Wait();
-            }
-            catch (Exception e)
-            {
-                // Flushing may fail.  We still have to close all our connections.
-                StorageDatabaseLogger.LogException(e);
-            }
-
-            lock (_connectionGate)
-            {
-                // Notify any outstanding async work that it should stop.
-                _shutdownTokenSource.Cancel();
-
-                // Go through all our pooled connections and close them.
-                while (_connectionsPool.Count > 0)
-                {
-                    var connection = _connectionsPool.Pop();
-                    connection.Close_OnlyForUseBySqlPersistentStorage();
-                }
-            }
-        }
-
-        /// <summary>
-        /// Gets a <see cref="SqlConnection"/> from the connection pool, or creates one if none are available.
-        /// </summary>
-        /// <remarks>
-        /// Database connections have a large amount of overhead, and should be returned to the pool when they are no
-        /// longer in use. In particular, make sure to avoid letting a connection lease cross an <see langword="await"/>
-        /// boundary, as it will prevent code in the asynchronous operation from using the existing connection.
-        /// </remarks>
-        private PooledConnection GetPooledConnection()
-            => new PooledConnection(this, GetConnection());
-
-        public void Initialize(Solution solution)
-        {
-            // Create a connection to the DB and ensure it has tables for the types we care about. 
-            using (var pooledConnection = GetPooledConnection())
-            {
-                var connection = pooledConnection.Connection;
-
-                // Enable write-ahead logging to increase write performance by reducing amount of disk writes,
-                // by combining writes at checkpoint, salong with using sequential-only writes to populate the log.
-                // Also, WAL allows for relaxed ("normal") "synchronous" mode, see below.
-                connection.ExecuteCommand("pragma journal_mode=wal", throwOnError: false);
-
-                // Set "synchronous" mode to "normal" instead of default "full" to reduce the amount of buffer flushing syscalls,
-                // significantly reducing both the blocked time and the amount of context switches.
-                // When coupled with WAL, this (according to https://sqlite.org/pragma.html#pragma_synchronous and 
-                // https://www.sqlite.org/wal.html#performance_considerations) is unlikely to significantly affect durability,
-                // while significantly increasing performance, because buffer flushing is done for each checkpoint, instead of each
-                // transaction. While some writes can be lost, they are never reordered, and higher layers will recover from that.
-                connection.ExecuteCommand("pragma synchronous=normal", throwOnError: false);
-
-                // First, create all our tables
-                connection.ExecuteCommand(
-$@"create table if not exists ""{StringInfoTableName}"" (
-    ""{DataIdColumnName}"" integer primary key autoincrement not null,
-    ""{DataColumnName}"" varchar)");
-
-                // Ensure that the string-info table's 'Value' column is defined to be 'unique'.
-                // We don't allow duplicate strings in this table.
-                connection.ExecuteCommand(
-$@"create unique index if not exists ""{StringInfoTableName}_{DataColumnName}"" on ""{StringInfoTableName}""(""{DataColumnName}"")");
-
-                connection.ExecuteCommand(
-$@"create table if not exists ""{SolutionDataTableName}"" (
-    ""{DataIdColumnName}"" varchar primary key not null,
-    ""{ChecksumColumnName}"" blob,
-    ""{DataColumnName}"" blob)");
-
-                connection.ExecuteCommand(
-$@"create table if not exists ""{ProjectDataTableName}"" (
-    ""{DataIdColumnName}"" integer primary key not null,
-    ""{ChecksumColumnName}"" blob,
-    ""{DataColumnName}"" blob)");
-
-                connection.ExecuteCommand(
-$@"create table if not exists ""{DocumentDataTableName}"" (
-    ""{DataIdColumnName}"" integer primary key not null,
-    ""{ChecksumColumnName}"" blob,
-    ""{DataColumnName}"" blob)");
-
-                // Also get the known set of string-to-id mappings we already have in the DB.
-                // Do this in one batch if possible.
-                var fetched = TryFetchStringTable(connection);
-
-                // If we weren't able to retrieve the entire string table in one batch,
-                // attempt to retrieve it for each 
-                var fetchStringTable = !fetched;
-
-                // Try to bulk populate all the IDs we'll need for strings/projects/documents.
-                // Bulk population is much faster than trying to do everything individually.
-                BulkPopulateIds(connection, solution, fetchStringTable);
-            }
-        }
-    }
-}
diff --git a/src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorageService.cs b/src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorageService.cs
deleted file mode 100644
index ca7d67bfd7..0000000000
--- a/src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorageService.cs
+++ /dev/null
@@ -1,162 +0,0 @@
-﻿// Copyright (c) Microsoft.  All Rights Reserved.  Licensed under the Apache License, Version 2.0.  See License.txt in the project root for license information.
-
-using System;
-using System.IO;
-using System.Runtime.InteropServices;
-using Microsoft.CodeAnalysis.Host;
-using Microsoft.CodeAnalysis.Options;
-using Microsoft.CodeAnalysis.Shared.Utilities;
-using Microsoft.CodeAnalysis.SolutionSize;
-using Microsoft.CodeAnalysis.Storage;
-using Roslyn.Utilities;
-
-namespace Microsoft.CodeAnalysis.SQLite
-{
-    internal partial class SQLitePersistentStorageService : AbstractPersistentStorageService
-    {
-        private const string LockFile = "db.lock";
-        private const string StorageExtension = "sqlite3";
-        private const string PersistentStorageFileName = "storage.ide";
-
-        private readonly IPersistentStorageFaultInjector _faultInjectorOpt;
-
-        [DllImport("kernel32.dll")]
-        private static extern IntPtr LoadLibrary(string dllToLoad);
-
-        private static bool TryInitializeLibraries() => s_initialized.Value;
-
-        private static readonly Lazy<bool> s_initialized = new Lazy<bool>(() => TryInitializeLibrariesLazy());
-
-        private static bool TryInitializeLibrariesLazy()
-        {
-            // Attempt to load the correct version of e_sqlite.dll.  That way when we call
-            // into SQLitePCL.Batteries_V2.Init it will be able to find it.
-            //
-            // Only do this on Windows when we can safely do the LoadLibrary call to this
-            // direct dll.  On other platforms, it is the responsibility of the host to ensure
-            // that the necessary sqlite library has already been loaded such that SQLitePCL.Batteries_V2
-            // will be able to call into it.
-            if (Environment.OSVersion.Platform == PlatformID.Win32NT)
-            {
-                var myFolder = Path.GetDirectoryName(
-                    typeof(SQLitePersistentStorage).Assembly.Location);
-
-                var is64 = IntPtr.Size == 8;
-                var subfolder = is64 ? "x64" : "x86";
-
-                LoadLibrary(Path.Combine(myFolder, subfolder, "e_sqlite3.dll"));
-            }
-
-            try
-            {
-                // Necessary to initialize SQLitePCL.
-                SQLitePCL.Batteries_V2.Init();
-            }
-            catch (Exception e) when (e is DllNotFoundException || e is EntryPointNotFoundException)
-            {
-                StorageDatabaseLogger.LogException(e);
-                return false;
-            }
-
-            return true;
-        }
-
-        public SQLitePersistentStorageService(
-            IOptionService optionService,
-            IPersistentStorageLocationService locationService,
-            ISolutionSizeTracker solutionSizeTracker)
-            : base(optionService, locationService, solutionSizeTracker)
-        {
-        }
-
-        public SQLitePersistentStorageService(
-            IOptionService optionService,
-            IPersistentStorageLocationService locationService,
-            ISolutionSizeTracker solutionSizeTracker,
-            IPersistentStorageFaultInjector faultInjector)
-            : this(optionService, locationService, solutionSizeTracker)
-        {
-            _faultInjectorOpt = faultInjector;
-        }
-
-        protected override string GetDatabaseFilePath(string workingFolderPath)
-        {
-            Contract.ThrowIfTrue(string.IsNullOrWhiteSpace(workingFolderPath));
-            return Path.Combine(workingFolderPath, StorageExtension, PersistentStorageFileName);
-        }
-
-        protected override bool TryOpenDatabase(
-            Solution solution, string workingFolderPath, string databaseFilePath, out IChecksummedPersistentStorage storage)
-        {
-            if (!TryInitializeLibraries())
-            {
-                // SQLite is not supported on the current platform
-                storage = null;
-                return false;
-            }
-
-            // try to get db ownership lock. if someone else already has the lock. it will throw
-            var dbOwnershipLock = TryGetDatabaseOwnership(databaseFilePath);
-            if (dbOwnershipLock == null)
-            {
-                storage = null;
-                return false;
-            }
-
-            SQLitePersistentStorage sqlStorage = null;
-            try
-            {
-                sqlStorage = new SQLitePersistentStorage(
-                     workingFolderPath, solution.FilePath, databaseFilePath, dbOwnershipLock, _faultInjectorOpt);
-
-                sqlStorage.Initialize(solution);
-
-            }
-            catch (Exception)
-            {
-                if (sqlStorage != null)
-                {
-                    // Dispose of the storage, releasing the ownership lock.
-                    sqlStorage.Dispose();
-                }
-                else
-                {
-                    // The storage was not created so nothing owns the lock.
-                    // Dispose the lock to allow reuse.
-                    dbOwnershipLock.Dispose();
-                }
-                throw;
-            }
-
-            storage = sqlStorage;
-            return true;
-        }
-
-        private static IDisposable TryGetDatabaseOwnership(string databaseFilePath)
-        {
-            return IOUtilities.PerformIO<IDisposable>(() =>
-            {
-                // make sure directory exist first.
-                EnsureDirectory(databaseFilePath);
-
-                return File.Open(
-                    Path.Combine(Path.GetDirectoryName(databaseFilePath), LockFile),
-                    FileMode.OpenOrCreate, FileAccess.ReadWrite, FileShare.None);
-            });
-        }
-
-        private static void EnsureDirectory(string databaseFilePath)
-        {
-            var directory = Path.GetDirectoryName(databaseFilePath);
-            if (Directory.Exists(directory))
-            {
-                return;
-            }
-
-            Directory.CreateDirectory(directory);
-        }
-
-        // Error occurred when trying to open this DB.  Try to remove it so we can create a good DB.
-        protected override bool ShouldDeleteDatabase(Exception exception) => true;
-    }
-}
diff --git a/src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage_BulkPopulateIds.cs b/src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage_BulkPopulateIds.cs
deleted file mode 100644
index 3ed8639ee9..0000000000
--- a/src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage_BulkPopulateIds.cs
+++ /dev/null
@@ -1,239 +0,0 @@
-﻿// Copyright (c) Microsoft.  All Rights Reserved.  Licensed under the Apache License, Version 2.0.  See License.txt in the project root for license information.
-
-using System;
-using System.Collections.Concurrent;
-using System.Collections.Generic;
-using Microsoft.CodeAnalysis.PooledObjects;
-using Microsoft.CodeAnalysis.SQLite.Interop;
-using Microsoft.CodeAnalysis.Storage;
-using Roslyn.Utilities;
-
-namespace Microsoft.CodeAnalysis.SQLite
-{
-    internal partial class SQLitePersistentStorage
-    {
-        private readonly ConcurrentDictionary<ProjectId, object> _projectBulkPopulatedLock = new ConcurrentDictionary<ProjectId, object>();
-        private readonly HashSet<ProjectId> _projectBulkPopulatedMap = new HashSet<ProjectId>();
-
-        /// <remarks>
-        /// We have a lot of ID information to put into the DB. IDs for all strings we intend to 
-        /// intern, as well as compound IDs for our projects and documents. Inserting these 
-        /// individually is far too slow as SQLite will lock the DB for each insert and will have
-        /// to do all the journalling work to ensure ACID semantics.  To avoid that, we attempt
-        /// to precompute all the information we'd need to put in the ID tables and perform it
-        /// all at once per project.
-        /// </remarks>
-        private void BulkPopulateIds(SqlConnection connection, Solution solution, bool fetchStringTable)
-        {
-            foreach (var project in solution.Projects)
-            {
-                BulkPopulateProjectIds(connection, project, fetchStringTable);
-            }
-        }
-
-        private void BulkPopulateProjectIds(SqlConnection connection, Project project, bool fetchStringTable)
-        {
-            // Ensure that only one caller is trying to bulk populate a project at a time.
-            var gate = _projectBulkPopulatedLock.GetOrAdd(project.Id, _ => new object());
-            lock (gate)
-            {
-                if (_projectBulkPopulatedMap.Contains(project.Id))
-                {
-                    // We've already bulk processed this project.  No need to do so again.
-                    return;
-                }
-
-                // Ensure our string table is up to date with the DB.  Note: we want to do this 
-                // to prevent the following problem:
-                //
-                // 1) Process1 and Process2 are concurrently attempting to bulk populate the DB.  Process1
-                // ends up populating the DB.  Process2 then tries to do the same, and gets a constraint
-                // violation because it is trying to add the same strings as Process1 did.  Because of the
-                // contraint violation, Process2 will back off to try again later.  Unless it actually gets
-                // the current string table, it will keep having problems trying to bulk populate.
-                if (fetchStringTable)
-                {
-                    if (!TryFetchStringTable(connection))
-                    {
-                        // Weren't able to fetch the string table.  Have to try this again
-                        // later once the DB frees up.
-                        return;
-                    }
-                }
-
-                if (!BulkPopulateProjectIdsWorker(connection, project))
-                {
-                    // Something went wrong.  Try to bulk populate this project later.
-                    return;
-                }
-
-                // Successfully bulk populated.  Mark as such so we don't bother doing this again.
-                _projectBulkPopulatedMap.Add(project.Id);
-            }
-        }
-
-        private static readonly ObjectPool<Dictionary<int, string>> s_dictionaryPool =
-            new ObjectPool<Dictionary<int, string>>(() => new Dictionary<int, string>());
-
-        /// <summary>
-        /// Returns 'true' if the bulk population succeeds, or false if it doesn't.
-        /// </summary>
-        private bool BulkPopulateProjectIdsWorker(SqlConnection connection, Project project)
-        {
-            // First, in bulk, get string-ids for all the paths and names for the project and documents.
-            if (!AddIndividualProjectAndDocumentComponentIds())
-            {
-                return false;
-            }
-
-            // Now, ensure we have the project id known locally.  We cannot do this until we've 
-            // gotten all the IDs for the individual project components as the project ID is built
-            // from a compound key using the IDs for the project's FilePath and Name.
-            //
-            // If this fails for any reason, we can't proceed.
-            var projectId = TryGetProjectId(connection, project);
-            if (projectId == null)
-            {
-                return false;
-            }
-
-            // Finally, in bulk, determine the final DB IDs for all our documents. We cannot do 
-            // this until we have the project-id as the document IDs are built from a compound
-            // ID including the project-id.
-            return AddDocumentIds();
-
-            // Local functions below.
-
-            // Use local functions so that other members of this class don't accidentally use these.
-            // There are invariants in the context of BulkPopulateProjectIdsWorker that these functions
-            // can depend on.
-            bool AddIndividualProjectAndDocumentComponentIds()
-            {
-                var stringsToAdd = new HashSet<string>();
-                AddIfUnknownId(project.FilePath, stringsToAdd);
-                AddIfUnknownId(project.Name, stringsToAdd);
-
-                foreach (var document in project.Documents)
-                {
-                    AddIfUnknownId(document.FilePath, stringsToAdd);
-                    AddIfUnknownId(document.Name, stringsToAdd);
-                }
-
-                return AddStrings(stringsToAdd);
-            }
-
-            bool AddStrings(HashSet<string> stringsToAdd)
-            {
-                if (stringsToAdd.Count > 0)
-                {
-                    using (var idToString = s_dictionaryPool.GetPooledObject())
-                    {
-                        try
-                        {
-                            connection.RunInTransaction(
-                                state =>
-                                {
-                                    foreach (var value in state.stringsToAdd)
-                                    {
-                                        var id = InsertStringIntoDatabase_MustRunInTransaction(state.connection, value);
-                                        state.idToString.Object.Add(id, value);
-                                    }
-                                },
-                                (stringsToAdd, connection, idToString));
-                        }
-                        catch (SqlException ex) when (ex.Result == Result.CONSTRAINT)
-                        {
-                            // Constraint exceptions are possible as we may be trying bulk insert 
-                            // strings while some other thread/process does the same.
-                            return false;
-                        }
-                        catch (Exception ex)
-                        {
-                            // Something failed. Log the issue, and let the caller know we should stop
-                            // with the bulk population.
-                            StorageDatabaseLogger.LogException(ex);
-                            return false;
-                        }
-
-                        // We succeeded inserting all the strings.  Ensure our local cache has all the
-                        // values we added.
-                        foreach (var kvp in idToString.Object)
-                        {
-                            _stringToIdMap[kvp.Value] = kvp.Key;
-                        }
-                    }
-                }
-
-                return true;
-            }
-
-            bool AddDocumentIds()
-            {
-                var stringsToAdd = new HashSet<string>();
-
-                foreach (var document in project.Documents)
-                {
-                    // Produce the string like "projId-docPathId-docNameId" so that we can get a
-                    // unique ID for it.
-                    AddIfUnknownId(GetDocumentIdString(document), stringsToAdd);
-                }
-
-                // Ensure we have unique IDs for all these document string ids.  If we fail to 
-                // bulk import these strings, we can't proceed.
-                if (!AddStrings(stringsToAdd))
-                {
-                    return false;
-                }
-
-                foreach (var document in project.Documents)
-                {
-                    // Get the integral ID for this document.  It's safe to directly index into
-                    // the map as we just successfully added these strings to the DB.
-                    var id = _stringToIdMap[GetDocumentIdString(document)];
-                    _documentIdToIdMap.TryAdd(document.Id, id);
-                }
-
-                return true;
-            }
-
-            string GetDocumentIdString(Document document)
-            {
-                // We should always be able to index directly into these maps.  This function is only
-                // ever called after we called AddIndividualProjectAndDocumentComponentIds.
-                var documentPathId = _stringToIdMap[document.FilePath];
-                var documentNameId = _stringToIdMap[document.Name];
-
-                var documentIdString = SQLitePersistentStorage.GetDocumentIdString(
-                    projectId.Value, documentPathId, documentNameId);
-                return documentIdString;
-            }
-
-            void AddIfUnknownId(string value, HashSet<string> stringsToAdd)
-            {
-                // Null strings are not supported at all.  Just ignore these. Any read/writes 
-                // to null values will fail and will return 'false/null' to indicate failure
-                // (which is part of the documented contract of the persistence layer API).
-                if (value == null)
-                {
-                    return;
-                }
-
-                if (!_stringToIdMap.TryGetValue(value, out var id))
-                {
-                    stringsToAdd.Add(value);
-                }
-                else
-                {
-                    // We did know about this string.  However, we want to ensure that the 
-                    // actual string instance we're pointing to is the one produced by the
-                    // rest of the workspace, and not by the database.  This way we don't
-                    // end up having tons of duplicate strings in the storage service.
-                    //
-                    // So overwrite whatever we have so far in the table so we can release
-                    // the DB strings.
-                    _stringToIdMap[value] = id;
-                }
-            }
-        }
-    }
-}
diff --git a/src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage_DocumentIds.cs b/src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage_DocumentIds.cs
deleted file mode 100644
index 35a889fad0..0000000000
--- a/src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage_DocumentIds.cs
+++ /dev/null
@@ -1,86 +0,0 @@
-﻿// Copyright (c) Microsoft.  All Rights Reserved.  Licensed under the Apache License, Version 2.0.  See License.txt in the project root for license information.
-
-using System.Collections.Concurrent;
-using Microsoft.CodeAnalysis.SQLite.Interop;
-
-namespace Microsoft.CodeAnalysis.SQLite
-{
-    internal partial class SQLitePersistentStorage
-    {
-        /// <summary>
-        /// Mapping from the workspace's ID for a document, to the ID we use in the DB for the document.
-        /// Kept locally so we don't have to hit the DB for the common case of trying to determine the 
-        /// DB id for a document.
-        /// </summary>
-        private readonly ConcurrentDictionary<DocumentId, int> _documentIdToIdMap = new ConcurrentDictionary<DocumentId, int>();
-
-        /// <summary>
-        /// Given a document, and the name of a stream to read/write, gets the integral DB ID to 
-        /// use to find the data inside the DocumentData table.
-        /// </summary>
-        private bool TryGetDocumentDataId(SqlConnection connection, Document document, string name, out long dataId)
-        {
-            dataId = 0;
-
-            // First, try to get all the IDs for our project in sync with the DB.
-            // This will only be expensive the first time we do this.  But will save
-            // us from tons of back-and-forth as any BG analyzer processes all the
-            // documents in a solution.
-            BulkPopulateProjectIds(connection, document.Project, fetchStringTable: true);
-
-            var documentId = TryGetDocumentId(connection, document);
-            var nameId = TryGetStringId(connection, name);
-            if (documentId == null || nameId == null)
-            {
-                return false;
-            }
-
-            // Our data ID is just a 64bit int combining the two 32bit values of our documentId and nameId.
-            dataId = CombineInt32ValuesToInt64(documentId.Value, nameId.Value);
-            return true;
-        }
-
-        private int? TryGetDocumentId(SqlConnection connection, Document document)
-        {
-            // First see if we've cached the ID for this value locally.  If so, just return
-            // what we already have.
-            if (_documentIdToIdMap.TryGetValue(document.Id, out var existingId))
-            {
-                return existingId;
-            }
-
-            var id = TryGetDocumentIdFromDatabase(connection, document);
-            if (id != null)
-            {
-                // Cache the value locally so we don't need to go back to the DB in the future.
-                _documentIdToIdMap.TryAdd(document.Id, id.Value);
-            }
-
-            return id;
-        }
-
-        private int? TryGetDocumentIdFromDatabase(SqlConnection connection, Document document)
-        {
-            var projectId = TryGetProjectId(connection, document.Project);
-            if (projectId == null)
-            {
-                return null;
-            }
-
-            // Key the document off its project id, and its path and name.  That way we work properly
-            // in host and test scenarios.
-            var documentPathId = TryGetStringId(connection, document.FilePath);
-            var documentNameId = TryGetStringId(connection, document.Name);
-
-            if (documentPathId == null || documentNameId == null)
-            {
-                return null;
-            }
-
-            // Unique identify the document through the key:  projectId-documentPathId-documentNameId
-            return TryGetStringId(
-                connection,
-                GetDocumentIdString(projectId.Value, documentPathId.Value, documentNameId.Value));
-        }
-    }
-}
diff --git a/src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage_DocumentSerialization.cs b/src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage_DocumentSerialization.cs
deleted file mode 100644
index da2edb5cef..0000000000
--- a/src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage_DocumentSerialization.cs
+++ /dev/null
@@ -1,49 +0,0 @@
-﻿// Copyright (c) Microsoft.  All Rights Reserved.  Licensed under the Apache License, Version 2.0.  See License.txt in the project root for license information.
-
-using System.IO;
-using System.Threading;
-using System.Threading.Tasks;
-using Microsoft.CodeAnalysis.SQLite.Interop;
-
-namespace Microsoft.CodeAnalysis.SQLite
-{
-    internal partial class SQLitePersistentStorage
-    {
-        public override Task<Checksum> ReadChecksumAsync(Document document, string name, CancellationToken cancellationToken)
-            => _documentAccessor.ReadChecksumAsync((document, name), cancellationToken);
-
-        public override Task<Stream> ReadStreamAsync(Document document, string name, Checksum checksum, CancellationToken cancellationToken = default)
-            => _documentAccessor.ReadStreamAsync((document, name), checksum, cancellationToken);
-
-        public override Task<bool> WriteStreamAsync(Document document, string name, Stream stream, Checksum checksum, CancellationToken cancellationToken = default)
-            => _documentAccessor.WriteStreamAsync((document, name), stream, checksum, cancellationToken);
-
-        /// <summary>
-        /// <see cref="Accessor{TKey, TWriteQueueKey, TDatabaseId}"/> responsible for storing and 
-        /// retrieving data from <see cref="DocumentDataTableName"/>.
-        /// </summary>
-        private class DocumentAccessor : Accessor<
-            (Document document, string name),
-            (DocumentId, string),
-            long>
-        {
-            public DocumentAccessor(SQLitePersistentStorage storage) : base(storage)
-            {
-            }
-
-            protected override string DataTableName => DocumentDataTableName;
-
-            protected override (DocumentId, string) GetWriteQueueKey((Document document, string name) key)
-                => (key.document.Id, key.name);
-
-            protected override bool TryGetDatabaseId(SqlConnection connection, (Document document, string name) key, out long dataId)
-                => Storage.TryGetDocumentDataId(connection, key.document, key.name, out dataId);
-
-            protected override void BindFirstParameter(SqlStatement statement, long dataId)
-                => statement.BindInt64Parameter(parameterIndex: 1, value: dataId);
-
-            protected override bool TryGetRowId(SqlConnection connection, long dataId, out long rowId)
-                => GetAndVerifyRowId(connection, dataId, out rowId);
-        }
-    }
-}
diff --git a/src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage_Helpers.cs b/src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage_Helpers.cs
deleted file mode 100644
index 93403d137c..0000000000
--- a/src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage_Helpers.cs
+++ /dev/null
@@ -1,153 +0,0 @@
-﻿// Copyright (c) Microsoft.  All Rights Reserved.  Licensed under the Apache License, Version 2.0.  See License.txt in the project root for license information.
-
-using System;
-using System.Collections.Generic;
-using System.IO;
-using System.Threading;
-using Roslyn.Utilities;
-using static System.FormattableString;
-
-namespace Microsoft.CodeAnalysis.SQLite
-{
-    internal partial class SQLitePersistentStorage
-    {
-        private static string GetProjectIdString(int projectPathId, int projectNameId)
-            => Invariant($"{projectPathId}-{projectNameId}");
-
-        private static string GetDocumentIdString(int projectId, int documentPathId, int documentNameId)
-            => Invariant($"{projectId}-{documentPathId}-{documentNameId}");
-
-        private static long CombineInt32ValuesToInt64(int v1, int v2)
-            => ((long)v1 << 32) | (long)v2;
-
-
-        private static (byte[] bytes, int length, bool fromPool) GetBytes(
-            Checksum checksumOpt, CancellationToken cancellationToken)
-        {
-            // If we weren't passed a checsum, just pass the singleton empty byte array.
-            // Note: we don't add this to/from our pool.  But it likely woudn't be a problem
-            // for us to do that as this instance can't actually be mutated since it's just
-            // an empty array.
-            if (checksumOpt == null)
-            {
-                return (Array.Empty<byte>(), length: 0, fromPool: false);
-            }
-
-            using (var stream = SerializableBytes.CreateWritableStream())
-            using (var writer = new ObjectWriter(stream, cancellationToken: cancellationToken))
-            {
-                checksumOpt.WriteTo(writer);
-                stream.Position = 0;
-                return GetBytes(stream);
-            }
-        }
-
-        private static (byte[] bytes, int length, bool fromPool) GetBytes(Stream stream)
-        {
-            // Attempt to copy into a pooled byte[] if the stream length is known and it's 
-            // less than 128k.  This accounts for 99%+ of all of our streams while keeping
-            // a generally small pool around (<10 items) when I've debugged VS.
-
-            if (stream.CanSeek)
-            {
-                if (stream.Length >= 0 && stream.Length <= int.MaxValue)
-                {
-                    var length = (int)stream.Length;
-                    byte[] bytes;
-                    bool fromPool;
-                    if (length <= MaxPooledByteArrayLength)
-                    {
-                        // use a pooled byte[] to store our data in.
-                        bytes = GetPooledBytes();
-                        fromPool = true;
-                    }
-                    else
-                    {
-                        // We knew the length, but it was large.  Copy the stream into that
-                        // array, but don't pool it so we don't hold onto huge arrays forever.
-                        bytes = new byte[length];
-                        fromPool = false;
-                    }
-
-                    CopyTo(stream, bytes, length);
-                    return (bytes, length, fromPool);
-                }
-            }
-
-            // Not something we could get the length of. Just copy the bytes out of the stream entirely.
-            using (var tempStream = new MemoryStream())
-            {
-                stream.CopyTo(tempStream);
-                var bytes = tempStream.ToArray();
-                return (bytes, bytes.Length, fromPool: false);
-            }
-        }
-
-        private static void CopyTo(Stream stream, byte[] bytes, int length)
-        {
-            var index = 0;
-            int read;
-            while (length > 0 && (read = stream.Read(bytes, index, length)) != 0)
-            {
-                index += read;
-                length -= read;
-            }
-        }
-
-        /// <summary>
-        /// Amount of time to wait between flushing writes to disk.  500ms means we can flush
-        /// writes to disk two times a second.
-        /// </summary>
-        private const int FlushAllDelayMS = 500;
-
-        /// <summary>
-        /// We use a pool to cache reads/writes that are less than 4k.  Testing with Roslyn,
-        /// 99% of all writes (48.5k out of 49.5k) are less than that size.  So this helps
-        /// ensure that we can pool as much as possible, without caching excessively large 
-        /// arrays (for example, Roslyn does write out nearly 50 chunks that are larger than
-        /// 100k each).
-        /// </summary>
-        internal const long MaxPooledByteArrayLength = 4 * 1024;
-
-        /// <summary>
-        /// The max amount of byte[]s we cache.  This caps our cache at 4MB while allowing
-        /// us to massively speed up writing (by batching writes).  Because we can write to
-        /// disk two times a second.  That means a total of 8MB/s that can be written to disk
-        /// using only our cache.  Given that Roslyn itself only writes about 50MB to disk
-        /// after several minutes of analysis, this amount of bandwidth is more than sufficient.
-        /// </summary>
-        private const int MaxPooledByteArrays = 1024;
-
-        private static readonly Stack<byte[]> s_byteArrayPool = new Stack<byte[]>();
-
-        internal static byte[] GetPooledBytes()
-        {
-            byte[] bytes;
-            lock (s_byteArrayPool)
-            {
-                if (s_byteArrayPool.Count > 0)
-                {
-                    bytes = s_byteArrayPool.Pop();
-                }
-                else
-                {
-                    bytes = new byte[MaxPooledByteArrayLength];
-                }
-            }
-
-            Array.Clear(bytes, 0, bytes.Length);
-            return bytes;
-        }
-
-        internal static void ReturnPooledBytes(byte[] bytes)
-        {
-            lock (s_byteArrayPool)
-            {
-                if (s_byteArrayPool.Count < MaxPooledByteArrays)
-                {
-                    s_byteArrayPool.Push(bytes);
-                }
-            }
-        }
-    }
-}
diff --git a/src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage_ProjectIds.cs b/src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage_ProjectIds.cs
deleted file mode 100644
index 7444fc33a7..0000000000
--- a/src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage_ProjectIds.cs
+++ /dev/null
@@ -1,79 +0,0 @@
-﻿// Copyright (c) Microsoft.  All Rights Reserved.  Licensed under the Apache License, Version 2.0.  See License.txt in the project root for license information.
-
-using System.Collections.Concurrent;
-using Microsoft.CodeAnalysis.SQLite.Interop;
-
-namespace Microsoft.CodeAnalysis.SQLite
-{
-    internal partial class SQLitePersistentStorage
-    {
-        /// <summary>
-        /// Mapping from the workspace's ID for a project, to the ID we use in the DB for the project.
-        /// Kept locally so we don't have to hit the DB for the common case of trying to determine the 
-        /// DB id for a project.
-        /// </summary>
-        private readonly ConcurrentDictionary<ProjectId, int> _projectIdToIdMap = new ConcurrentDictionary<ProjectId, int>();
-
-        /// <summary>
-        /// Given a project, and the name of a stream to read/write, gets the integral DB ID to 
-        /// use to find the data inside the ProjectData table.
-        /// </summary>
-        private bool TryGetProjectDataId(SqlConnection connection, Project project, string name, out long dataId)
-        {
-            dataId = 0;
-
-            // First, try to get all the IDs for this project in sync with the DB.
-            // This will only be expensive the first time we do this.  But will save
-            // us from tons of back-and-forth as any BG analyzer processes all the
-            // documents in a solution.
-            BulkPopulateProjectIds(connection, project, fetchStringTable: true);
-
-            var projectId = TryGetProjectId(connection, project);
-            var nameId = TryGetStringId(connection, name);
-            if (projectId == null || nameId == null)
-            {
-                return false;
-            }
-
-            // Our data ID is just a 64bit int combining the two 32bit values of our projectId and nameId.
-            dataId = CombineInt32ValuesToInt64(projectId.Value, nameId.Value);
-            return true;
-        }
-
-        private int? TryGetProjectId(SqlConnection connection, Project project)
-        {
-            // First see if we've cached the ID for this value locally.  If so, just return
-            // what we already have.
-            if (_projectIdToIdMap.TryGetValue(project.Id, out var existingId))
-            {
-                return existingId;
-            }
-
-            var id = TryGetProjectIdFromDatabase(connection, project);
-            if (id != null)
-            {
-                // Cache the value locally so we don't need to go back to the DB in the future.
-                _projectIdToIdMap.TryAdd(project.Id, id.Value);
-            }
-
-            return id;
-        }
-
-        private int? TryGetProjectIdFromDatabase(SqlConnection connection, Project project)
-        {
-            // Key the project off both its path and name.  That way we work properly
-            // in host and test scenarios.
-            var projectPathId = TryGetStringId(connection, project.FilePath);
-            var projectNameId = TryGetStringId(connection, project.Name);
-
-            if (projectPathId == null || projectNameId == null)
-            {
-                return null;
-            }
-
-            return TryGetStringId(
-                connection,
-                GetProjectIdString(projectPathId.Value, projectNameId.Value));
-        }
-    }
-}
diff --git a/src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage_ProjectSerialization.cs b/src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage_ProjectSerialization.cs
deleted file mode 100644
index 1f0861a1c0..0000000000
--- a/src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage_ProjectSerialization.cs
+++ /dev/null
@@ -1,49 +0,0 @@
-﻿// Copyright (c) Microsoft.  All Rights Reserved.  Licensed under the Apache License, Version 2.0.  See License.txt in the project root for license information.
-
-using System.IO;
-using System.Threading;
-using System.Threading.Tasks;
-using Microsoft.CodeAnalysis.SQLite.Interop;
-
-namespace Microsoft.CodeAnalysis.SQLite
-{
-    internal partial class SQLitePersistentStorage
-    {
-        public override Task<Checksum> ReadChecksumAsync(Project project, string name, CancellationToken cancellationToken)
-            => _projectAccessor.ReadChecksumAsync((project, name), cancellationToken);
-
-        public override Task<Stream> ReadStreamAsync(Project project, string name, Checksum checksum, CancellationToken cancellationToken = default)
-            => _projectAccessor.ReadStreamAsync((project, name), checksum, cancellationToken);
-
-        public override Task<bool> WriteStreamAsync(Project project, string name, Stream stream, Checksum checksum, CancellationToken cancellationToken = default)
-            => _projectAccessor.WriteStreamAsync((project, name), stream, checksum, cancellationToken);
-
-        /// <summary>
-        /// <see cref="Accessor{TKey, TWriteQueueKey, TDatabaseId}"/> responsible for storing and
-        /// retrieving data from <see cref="ProjectDataTableName"/>.
-        /// </summary>
-        private class ProjectAccessor : Accessor<
-            (Project project, string name),
-            (ProjectId projectId, string name),
-            long>
-        {
-            public ProjectAccessor(SQLitePersistentStorage storage) : base(storage)
-            {
-            }
-
-            protected override string DataTableName => ProjectDataTableName;
-
-            protected override (ProjectId projectId, string name) GetWriteQueueKey((Project project, string name) key)
-                => (key.project.Id, key.name);
-
-            protected override bool TryGetDatabaseId(SqlConnection connection, (Project project, string name) key, out long dataId)
-                => Storage.TryGetProjectDataId(connection, key.project, key.name, out dataId);
-
-            protected override void BindFirstParameter(SqlStatement statement, long dataId)
-                => statement.BindInt64Parameter(parameterIndex: 1, value: dataId);
-
-            protected override bool TryGetRowId(SqlConnection connection, long dataId, out long rowId)
-                => GetAndVerifyRowId(connection, dataId, out rowId);
-        }
-    }
-}
diff --git a/src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage_SolutionSerialization.cs b/src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage_SolutionSerialization.cs
deleted file mode 100644
index d40d2f799c..0000000000
--- a/src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage_SolutionSerialization.cs
+++ /dev/null
@@ -1,48 +0,0 @@
-﻿// Copyright (c) Microsoft.  All Rights Reserved.  Licensed under the Apache License, Version 2.0.  See License.txt in the project root for license information.
-
-using System.IO;
-using System.Threading;
-using System.Threading.Tasks;
-using Microsoft.CodeAnalysis.SQLite.Interop;
-
-namespace Microsoft.CodeAnalysis.SQLite
-{
-    internal partial class SQLitePersistentStorage
-    {
-        public override Task<Checksum> ReadChecksumAsync(string name, CancellationToken cancellationToken)
-            => _solutionAccessor.ReadChecksumAsync(name, cancellationToken);
-
-        public override Task<Stream> ReadStreamAsync(string name, Checksum checksum, CancellationToken cancellationToken)
-            => _solutionAccessor.ReadStreamAsync(name, checksum, cancellationToken);
-
-        public override Task<bool> WriteStreamAsync(string name, Stream stream, Checksum checksum, CancellationToken cancellationToken)
-            => _solutionAccessor.WriteStreamAsync(name, stream, checksum, cancellationToken);
-
-        /// <summary>
-        /// <see cref="Accessor{TKey, TWriteQueueKey, TDatabaseId}"/> responsible for storing and 
-        /// retrieving data from <see cref="SolutionDataTableName"/>.  Note that with the Solution 
-        /// table there is no need for key->id translation.  i.e. the key acts as the ID itself.
-        /// </summary>
-        private class SolutionAccessor : Accessor<string, string, string>
-        {
-            public SolutionAccessor(SQLitePersistentStorage storage) : base(storage)
-            {
-            }
-
-            protected override string DataTableName => SolutionDataTableName;
-
-            protected override string GetWriteQueueKey(string key)
-                => key;
-
-            protected override bool TryGetDatabaseId(SqlConnection connection, string key, out string dataId)
-            {
-                // For the SolutionDataTable the key itself acts as the data-id.
-                dataId = key;
-                return true;
-            }
-
-            protected override void BindFirstParameter(SqlStatement statement, string dataId)
-                => statement.BindStringParameter(parameterIndex: 1, value: dataId);
-        }
-    }
-}
diff --git a/src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage_StringIds.cs b/src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage_StringIds.cs
deleted file mode 100644
index c4eccf0630..0000000000
--- a/src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage_StringIds.cs
+++ /dev/null
@@ -1,179 +0,0 @@
-﻿// Copyright (c) Microsoft.  All Rights Reserved.  Licensed under the Apache License, Version 2.0.  See License.txt in the project root for license information.
-
-using System;
-using System.Collections.Concurrent;
-using Microsoft.CodeAnalysis.SQLite.Interop;
-using Microsoft.CodeAnalysis.Storage;
-using Roslyn.Utilities;
-
-namespace Microsoft.CodeAnalysis.SQLite
-{
-    internal partial class SQLitePersistentStorage
-    {
-        private readonly ConcurrentDictionary<string, int> _stringToIdMap = new ConcurrentDictionary<string, int>();
-
-        private bool TryFetchStringTable(SqlConnection connection)
-        {
-            try
-            {
-                using (var resettableStatement = connection.GetResettableStatement(_select_star_from_0))
-                {
-                    var statement = resettableStatement.Statement;
-                    while (statement.Step() == Result.ROW)
-                    {
-                        var id = statement.GetInt32At(columnIndex: 0);
-                        var value = statement.GetStringAt(columnIndex: 1);
-
-                        // Note that TryAdd won't overwrite an existing string->id pair.  That's what
-                        // we want.  we don't want the strings we've allocated from the DB to be what
-                        // we hold onto.  We'd rather hold onto the strings we get from sources like
-                        // the workspaces.  This helps avoid unnecessary string instance duplication.
-                        _stringToIdMap.TryAdd(value, id);
-                    }
-                }
-
-                return true;
-            }
-            catch (SqlException e) when (e.Result == Result.BUSY || e.Result == Result.LOCKED)
-            {
-                // Couldn't get access to sql database to fetch the string table.  
-                // Try again later.
-                return false;
-            }
-        }
-
-        private int? TryGetStringId(SqlConnection connection, string value)
-        {
-            // Null strings are not supported at all.  Just ignore these. Any read/writes 
-            // to null values will fail and will return 'false/null' to indicate failure
-            // (which is part of the documented contract of the persistence layer API).
-            if (value == null)
-            {
-                return null;
-            }
-
-            // First see if we've cached the ID for this value locally.  If so, just return
-            // what we already have.
-            if (_stringToIdMap.TryGetValue(value, out var existingId))
-            {
-                return existingId;
-            }
-
-            // Otherwise, try to get or add the string to the string table in the database.
-            var id = TryGetStringIdFromDatabase(connection, value);
-            if (id != null)
-            {
-                _stringToIdMap[value] = id.Value;
-            }
-
-            return id;
-        }
-
-        private int? TryGetStringIdFromDatabase(SqlConnection connection, string value)
-        {
-            // First, check if we can find that string in the string table.
-            var stringId = TryGetStringIdFromDatabaseWorker(connection, value, canReturnNull: true);
-            if (stringId != null)
-            {
-                // Found the value already in the db.  Another process (or thread) might have added it.
-                // We're done at this point.
-                return stringId;
-            }
-
-            // The string wasn't in the db string table.  Add it.  Note: this may fail if some
-            // other thread/process beats us there as this table has a 'unique' constraint on the
-            // values.
-            try
-            {
-                stringId = connection.RunInTransaction(
-                    state => InsertStringIntoDatabase_MustRunInTransaction(state.connection, state.value),
-                    (connection, value));
-
-                Contract.ThrowIfTrue(stringId == null);
-                return stringId;
-            }
-            catch (SqlException ex) when (ex.Result == Result.CONSTRAINT)
-            {
-                // We got a constraint violation.  This means someone else beat us to adding this
-                // string to the string-table.  We should always be able to find the string now.
-                stringId = TryGetStringIdFromDatabaseWorker(connection, value, canReturnNull: false);
-                return stringId;
-            }
-            catch (Exception ex)
-            {
-                // Some other error occurred.  Log it and return nothing.
-                StorageDatabaseLogger.LogException(ex);
-            }
-
-            return null;
-        }
-
-        private int InsertStringIntoDatabase_MustRunInTransaction(SqlConnection connection, string value)
-        {
-            if (!connection.IsInTransaction)
-            {
-                throw new InvalidOperationException("Must call this while connection has transaction open");
-            }
-
-            var id = -1;
-
-            using (var resettableStatement = connection.GetResettableStatement(_insert_into_0_1_values))
-            {
-                var statement = resettableStatement.Statement;
-
-                // SQLite bindings are 1-based.
-                statement.BindStringParameter(parameterIndex: 1, value: value);
-
-                // Try to insert the value.  This may throw a constraint exception if some
-                // other process beat us to this string.
-                statement.Step();
-
-                // Successfully added the string.  The ID for it can be retrieved as the LastInsertRowId
-                // for the db.  This is also safe to call because we must be in a transaction when this
-                // is invoked.
-                id = connection.LastInsertRowId();
-            }
-
-            Contract.ThrowIfTrue(id == -1);
-            return id;
-        }
-
-        private int? TryGetStringIdFromDatabaseWorker(
-            SqlConnection connection, string value, bool canReturnNull)
-        {
-            try
-            {
-                using (var resettableStatement = connection.GetResettableStatement(_select_star_from_0_where_1_limit_one))
-                {
-                    var statement = resettableStatement.Statement;
-
-                    // SQLite's binding indices are 1-based. 
-                    statement.BindStringParameter(parameterIndex: 1, value: value);
-
-                    var stepResult = statement.Step();
-                    if (stepResult == Result.ROW)
-                    {
-                        return statement.GetInt32At(columnIndex: 0);
-                    }
-                }
-            }
-            catch (Exception ex)
-            {
-                // If we simply failed to even talk to the DB then we have to bail out.  There's
-                // nothing we can accomplish at this point.
-                StorageDatabaseLogger.LogException(ex);
-                return null;
-            }
-
-            // No item with this value in the table.
-            if (canReturnNull)
-            {
-                return null;
-            }
-
-            // This should not be possible.  We only called here if we got a constraint violation.
-            // So how could we then not find the string in the table?
-            throw new InvalidOperationException();
-        }
-    }
-}
diff --git a/src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage_WriteBatching.cs b/src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage_WriteBatching.cs
deleted file mode 100644
index 26aafcf3a6..0000000000
--- a/src/Workspaces/Core/Portable/Storage/SQLite/SQLitePersistentStorage_WriteBatching.cs
+++ /dev/null
@@ -1,245 +0,0 @@
-﻿// Copyright (c) Microsoft.  All Rights Reserved.  Licensed under the Apache License, Version 2.0.  See License.txt in the project root for license information.
-
-using System;
-using System.Collections.Generic;
-using System.Diagnostics;
-using System.Threading;
-using System.Threading.Tasks;
-using Microsoft.CodeAnalysis.PooledObjects;
-using Microsoft.CodeAnalysis.SQLite.Interop;
-using Microsoft.CodeAnalysis.Storage;
-using Roslyn.Utilities;
-
-namespace Microsoft.CodeAnalysis.SQLite
-{
-    internal partial class SQLitePersistentStorage
-    {
-        /// <summary>
-        /// Lock protecting the write queues and <see cref="_flushAllTask"/>.
-        /// </summary>
-        private readonly SemaphoreSlim _writeQueueGate = new SemaphoreSlim(initialCount: 1);
-
-        /// <summary>
-        /// Task kicked off to actually do the work of flushing all data to the DB.
-        /// </summary>
-        private Task _flushAllTask;
-
-        private async Task AddWriteTaskAsync<TKey>(
-            MultiDictionary<TKey, Action<SqlConnection>> queue,
-            TKey key, Action<SqlConnection> action,
-            CancellationToken cancellationToken)
-        {
-            using (await _writeQueueGate.DisposableWaitAsync(cancellationToken).ConfigureAwait(false))
-            {
-                queue.Add(key, action);
-
-                // If we don't have an outstanding request to write the queue to the DB
-                // then create one to run a short while from now.  If there is an outstanding
-                // request, then it will see this write request when it runs.
-                if (_flushAllTask == null)
-                {
-                    var token = _shutdownTokenSource.Token;
-                    _flushAllTask =
-                        Task.Delay(FlushAllDelayMS, token)
-                            .ContinueWith(
-                                async _ => await FlushAllPendingWritesAsync(token).ConfigureAwait(false),
-                                token,
-                                TaskContinuationOptions.None,
-                                TaskScheduler.Default);
-                }
-            }
-        }
-
-        private async Task FlushSpecificWritesAsync<TKey>(
-            MultiDictionary<TKey, Action<SqlConnection>> keyToWriteActions,
-            Dictionary<TKey, Task> keyToWriteTask,
-            TKey key,
-            CancellationToken cancellationToken)
-        {
-            var writesToProcess = ArrayBuilder<Action<SqlConnection>>.GetInstance();
-            try
-            {
-                await FlushSpecificWritesAsync(keyToWriteActions, keyToWriteTask, key, writesToProcess, cancellationToken).ConfigureAwait(false);
-            }
-            finally
-            {
-                writesToProcess.Free();
-            }
-        }
-
-        [PerformanceSensitive("https://github.com/dotnet/roslyn/issues/36114", AllowCaptures = false)]
-        private async Task FlushSpecificWritesAsync<TKey>(
-            MultiDictionary<TKey, Action<SqlConnection>> keyToWriteActions,
-            Dictionary<TKey, Task> keyToWriteTask,
-            TKey key,
-            ArrayBuilder<Action<SqlConnection>> writesToProcess,
-            CancellationToken cancellationToken)
-        {
-            // Get's the task representing the current writes being performed by another
-            // thread for this queue+key, and a TaskCompletionSource we can use to let
-            // other threads know about our own progress writing any new writes in this queue.
-            var (previousWritesTask, taskCompletionSource) = await GetWriteTaskAsync(keyToWriteActions, keyToWriteTask, key, writesToProcess, cancellationToken).ConfigureAwait(false);
-            try
-            {
-                // Wait for all previous writes to be flushed.
-                await previousWritesTask.ConfigureAwait(false);
-
-                if (writesToProcess.Count == 0)
-                {
-                    // No additional writes for us to flush.  We can immediately bail out.
-                    Debug.Assert(taskCompletionSource == null);
-                    return;
-                }
-
-                // Now, if we have writes of our own, do them on this thread.
-                // 
-                // Note: this flushing is not cancellable.  We've already removed the
-                // writes from the write queue.  If we were not to write them out we
-                // would be losing data.
-                Debug.Assert(taskCompletionSource != null);
-
-                using (var pooledConnection = GetPooledConnection())
-                {
-                    ProcessWriteQueue(pooledConnection.Connection, writesToProcess);
-                }
-            }
-            catch (OperationCanceledException ex)
-            {
-                taskCompletionSource?.TrySetCanceled(ex.CancellationToken);
-            }
-            catch (Exception ex)
-            {
-                taskCompletionSource?.TrySetException(ex);
-            }
-            finally
-            {
-                // Mark our TCS as completed.  Any other threads waiting on us will now be able
-                // to proceed.
-                taskCompletionSource?.TrySetResult(0);
-            }
-        }
-
-        [PerformanceSensitive("https://github.com/dotnet/roslyn/issues/36114", OftenCompletesSynchronously = true)]
-        private async ValueTask<(Task previousTask, TaskCompletionSource<int> taskCompletionSource)> GetWriteTaskAsync<TKey>(
-            MultiDictionary<TKey, Action<SqlConnection>> keyToWriteActions,
-            Dictionary<TKey, Task> keyToWriteTask,
-            TKey key,
-            ArrayBuilder<Action<SqlConnection>> writesToProcess,
-            CancellationToken cancellationToken)
-        {
-            // Have to acquire the semaphore.  We're going to mutate the shared 'keyToWriteActions'
-            // and 'keyToWriteTask' collections.
-            //
-            // Note: by blocking on _writeQueueGate we are guaranteed to see all the writes
-            // performed by FlushAllPendingWritesAsync.
-            using (await _writeQueueGate.DisposableWaitAsync(cancellationToken).ConfigureAwait(false))
-            {
-                // Get the writes we need to process. 
-                // Note: explicitly foreach so we operate on the struct enumerator for
-                // MultiDictionary.ValueSet.
-                var actions = keyToWriteActions[key];
-                writesToProcess.EnsureCapacity(writesToProcess.Count + actions.Count);
-                foreach (var action in actions)
-                {
-                    writesToProcess.Add(action);
-                }
-
-                // and clear them from the queues so we don't process things multiple times.
-                keyToWriteActions.Remove(key);
-
-                // Find the existing task responsible for writing to this queue.
-                var existingWriteTask = keyToWriteTask.TryGetValue(key, out var task)
-                    ? task
-                    : Task.CompletedTask;
-
-                if (writesToProcess.Count == 0)
-                {
-                    // We have no writes of our own.  But there may be an existing task that
-                    // is writing out this queue.   Return this so our caller can wait for
-                    // all existing writes to complete.
-                    return (previousTask: existingWriteTask, taskCompletionSource: null);
-                }
-
-                // Create a TCS that represents our own work writing out "writesToProcess".
-                // Store it in keyToWriteTask so that if other threads come along, they'll
-                // wait for us to complete before doing their own reads/writes on this queue.
-                var localCompletionSource = new TaskCompletionSource<int>();
-
-                keyToWriteTask[key] = localCompletionSource.Task;
-
-                return (previousTask: existingWriteTask, taskCompletionSource: localCompletionSource);
-            }
-        }
-
-        private async Task FlushAllPendingWritesAsync(CancellationToken cancellationToken)
-        {
-            // Copy the work from _writeQueue to a local list that we can process.
-            var writesToProcess = ArrayBuilder<Action<SqlConnection>>.GetInstance();
-            try
-            {
-                using (await _writeQueueGate.DisposableWaitAsync(cancellationToken).ConfigureAwait(false))
-                {
-                    // Copy the pending work the accessors have to the local copy.
-                    _solutionAccessor.AddAndClearAllPendingWrites(writesToProcess);
-                    _projectAccessor.AddAndClearAllPendingWrites(writesToProcess);
-                    _documentAccessor.AddAndClearAllPendingWrites(writesToProcess);
-
-                    // Indicate that there is no outstanding write task.  The next request to 
-                    // write will cause one to be kicked off.
-                    _flushAllTask = null;
-
-                    // Note: we keep the lock while we're writing all.  That way if any reads come
-                    // in and want to wait for the respective keys to be written, they will see the
-                    // results of our writes after the lock is released.  Note: this is slightly
-                    // heavyweight.  But as we're only doing these writes in bulk a couple of times
-                    // a second max, this should not be an area of contention.
-                    if (writesToProcess.Count > 0)
-                    {
-                        using (var pooledConnection = GetPooledConnection())
-                        {
-                            ProcessWriteQueue(pooledConnection.Connection, writesToProcess);
-                        }
-                    }
-                }
-            }
-            finally
-            {
-                writesToProcess.Free();
-            }
-        }
-
-        private void ProcessWriteQueue(
-            SqlConnection connection,
-            ArrayBuilder<Action<SqlConnection>> writesToProcess)
-        {
-            if (writesToProcess.Count == 0)
-            {
-                return;
-            }
-
-            if (_shutdownTokenSource.Token.IsCancellationRequested)
-            {
-                // Don't actually try to perform any writes if we've been asked to shutdown.
-                return;
-            }
-
-            try
-            {
-                // Create a transaction and perform all writes within it.
-                connection.RunInTransaction(
-                    state =>
-                    {
-                        foreach (var action in state.writesToProcess)
-                        {
-                            action(state.connection);
-                        }
-                    },
-                    (writesToProcess, connection));
-            }
-            catch (Exception ex)
-            {
-                StorageDatabaseLogger.LogException(ex);
-            }
-        }
-    }
-}
-- 
2.17.1

